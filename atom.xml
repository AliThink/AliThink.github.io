<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>The  Force  Awakens
</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="/"/>
  <updated>2019-03-25T08:36:14.005Z</updated>
  <id>/</id>
  
  <author>
    <name>AliThink</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习问题决策flow</title>
    <link href="/2019/03/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98%E5%86%B3%E7%AD%96flow/"/>
    <id>/2019/03/25/机器学习问题决策flow/</id>
    <published>2019-03-25T08:29:32.000Z</published>
    <updated>2019-03-25T08:36:14.005Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-流程概述"><a href="#1-流程概述" class="headerlink" title="1.流程概述"></a>1.流程概述</h2><p><img src="https://i.loli.net/2019/03/25/5c9892d824801.png" alt="机器学习flo"></p><h2 id="2-图片引用"><a href="#2-图片引用" class="headerlink" title="2. 图片引用"></a>2. 图片引用</h2><p><img src="https://i.loli.net/2019/03/25/5c9892d778c5b.png" alt="1"></p><p><img src="https://i.loli.net/2019/03/25/5c9892d7e4943.png" alt="2"></p><p><img src="https://i.loli.net/2019/03/25/5c9892d763067.png" alt="3"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-流程概述&quot;&gt;&lt;a href=&quot;#1-流程概述&quot; class=&quot;headerlink&quot; title=&quot;1.流程概述&quot;&gt;&lt;/a&gt;1.流程概述&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/03/25/5c9892d824801.
      
    
    </summary>
    
      <category term="ML" scheme="/categories/ML/"/>
    
    
  </entry>
  
  <entry>
    <title>《零售新科学》读书笔记</title>
    <link href="/2019/01/31/%E3%80%8A%E9%9B%B6%E5%94%AE%E6%96%B0%E7%A7%91%E5%AD%A6%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>/2019/01/31/《零售新科学》读书笔记/</id>
    <published>2019-01-31T01:52:22.000Z</published>
    <updated>2019-01-31T01:53:13.129Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>前三章讲述了数据决策的工具方法。后面则更多的是讲述如何让这些科学决策方法在企业中顺畅的落地实施。<br>（如果有个电商案例的讲解就更好了。。而且很多工具方法，书中也说了更适用于用户需求相对稳定的品类，不适用于鞋服这类用户需求变化较频繁的品类🤣。同时深感线下零售商的不易，像是店铺分货、本地化等场景线上是无需涉及的。）</p><h2 id="笔记随想"><a href="#笔记随想" class="headerlink" title="笔记随想"></a>笔记随想</h2><ul><li>现货率对毛利净利的影响。<blockquote><p>缺货利润损失的考量，这块线上能好一些，比如大活动的缺货预售，能起到一定缓冲作用，但仍会面临用户因时间成本造成流失的利润损失。</p></blockquote></li></ul><ul><li><p>供需匹配能力。</p></li><li><p>较稳定的需求影响因素: 季节性，尺码组合，特定店铺的畅销产品类型，价格弹性，品类增长趋势。</p></li><li><p>单品月销较少，聚合相似店铺相似单品。</p><blockquote><p>品类预测要跟进，作为单品预测的重要特征。</p></blockquote></li></ul><ul><li>数据形成背后的根源和成因(销售条件)<blockquote><p>记录跟丰富的销售动作数据，比如打折促销、广告投放等。<br><br>价格，现货率，天气，竞争对手活动，理解每个因素是如何影响历史销量的以及影响的程度，并对因素未来影响销量进行预判和作出合理假设。</p></blockquote></li></ul><ul><li>库存增长对销售的正相关<blockquote><p>库存增长会减少缺货利润的损失，但会增加清仓的成本。</p></blockquote></li></ul><ul><li><p>销售成本</p></li><li><p>修正库存周转率AIT</p><blockquote><p>公式略复杂，由最小二乘法推出系数，据说效果比较好，增加一些影响库存水平的因变量。</p></blockquote></li></ul><ul><li>品类规划:战略层，战术层<blockquote><p>战略层：结合趋势，预测品类未来表现。<br><br>战术层：选品。</p></blockquote></li></ul><ul><li><p>销存比RST分段 划分高中低</p></li><li><p>考虑高频用户感受</p></li><li><p>将商品看作是属性的集合体，观察这些属性在历史的表现，占比等</p><blockquote><p>单一属性历史表现的参考意义，组合情况在历史数据中的缺失。<br><br>丰富的属性利于相似品的圈定，进而便于为新品寻求近似历史数据参考。</p></blockquote></li></ul><ul><li>新sku 需求预估<blockquote><p>需求份额估算用在电商类目需求估算中，缺失类目的需求估算。</p></blockquote></li></ul><ul><li>本地化策略运用于排除主力sku后的剩余收益提升空间<blockquote><p>主力款头部款，采用本地化策略效果甚微。反观电商，地域上的限制被打破了。</p></blockquote></li></ul><ul><li><p>基于概率加权需求的风险对冲模型，计算折扣与缺货利润损失，追求最大化</p></li><li><p>伽马分布 拓展到近似正则的范围</p></li><li><p>开季两周更新预测</p><blockquote><p>新品预测的误差率基本在50%以上，但稍微结合一些开季后的数据（结合补货提前期）即可大幅降低误差率。（开季时间是否有所留存，还是只能从销量表中进行推算）</p></blockquote></li></ul><ul><li><p>降价 销售提升系数</p></li><li><p>每个品类适合用于做预测的时间段</p><blockquote><p>韩都每个品类的补货提前期</p></blockquote></li></ul><ul><li>寻找推拉边界，预测那些提前期长，可预测的部分<blockquote><p>例如储备一些未上色的基础面料（提前期长，可预测性强），将上色流程放到定制化中，可以更快的结合当季需求的变化，进行快速生产。（不过仅限于有生产加工能力的厂商，全走供应商模式的厂商边界可调节程度有限）</p></blockquote></li></ul><ul><li>充分授权，较少沟通成本<blockquote><p>目前韩都的补货决策流程是怎样的，小组是否可以高效决策货品的返单。</p></blockquote></li></ul><ul><li>员工工资作为能力的一种划分标准<blockquote><p>员工工资提升与销售额提升的相关性曲线</p></blockquote></li></ul><ul><li><p>RFID溯源</p></li><li><p>对预测结果进行量化提升实施信心</p><blockquote><p>给出合理量化后结果的方案更容易推进，比如执行这个方案后，销售额会提升xx。<br><br>如何进行结果量化是一门学问，也可以作为模型最终效果评估的一个指标。<br><br>随着量化结果的达成，也会逐渐建立方案实施的信心。</p></blockquote></li></ul><ul><li>从专家们不乐意乏味的工作入手，比如尺码优化<blockquote><p>直接跟业务专家竞争关系的介入，可能会引起方案推进的阻力。不如挑选一些小的点，专家们比较『厌烦』去做的点，从这些点开始实践。成功了，建立下一步实践的信心；失败了，还可以失败于无声（毕竟没人关注这块🤪）。</p></blockquote></li></ul><h2 id="Get"><a href="#Get" class="headerlink" title="Get"></a>Get</h2><ul><li>各种数据决策分析方法。</li><li>库存的重要意义。大量备货是销量预测、柔性供应链之后保障销售的最后防线，但也是风险最高不得已的手段。。</li><li>方案推进远比掌握这些数据决策方法要难得多得多。</li><li>学会用量化的思维去推进。</li><li>要做品类预测了</li><li>。。。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;前三章讲述了数据决策的工具方法。后面则更多的是讲述如何让这些科学决策方法在企业中顺畅的落地实施。&lt;br&gt;（如果有个电商案例的讲解就更好了。。
      
    
    </summary>
    
      <category term="读过的书" scheme="/categories/%E8%AF%BB%E8%BF%87%E7%9A%84%E4%B9%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>机器学习从业者们的那些事儿</title>
    <link href="/2019/01/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%8E%E4%B8%9A%E8%80%85%E4%BB%AC%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/"/>
    <id>/2019/01/31/机器学习从业者们的那些事儿/</id>
    <published>2019-01-31T01:48:45.000Z</published>
    <updated>2019-01-31T01:51:26.055Z</updated>
    
    <content type="html"><![CDATA[<p><strong>明确工作问题</strong>、收集并清洗数据、搭建模型、得出结果并<strong>监测变化</strong>，这些过程通常会以不同形式相互连接，很难单独拿出来作为研究对象。</p><h2 id="当机器学习项目失败时"><a href="#当机器学习项目失败时" class="headerlink" title="当机器学习项目失败时"></a>当机器学习项目失败时</h2><p>机器学习项目失败的情况有以下这么几种：</p><ul><li>当数据科学团队搭建了一个从未用过的工具。但是公司的其他部门并不知道他们做了什么，有些数据科学家也并不清楚这些成果能否用于实际生产中。</li><li>当数据科学家们创造模型的速度快于将其投入生产的速度，就会产生积压。</li><li>数据基础架构工程师和数据科学家是分开的。通道中没有数据时，数据科学家会要求数据基础架构工程师获取。</li><li>当公司最终确定产品X的功能后，他们需要数据科学家收集支持这项决策的数据。数据科学家认为产品经理会忽略那些与决定相反的数据，而产品经理会认为数据科学家忽略商业逻辑。</li><li>数据科学团队面试了一位数学建模、工程技术能力都很好的候选人。确定录用后加入到垂直应用产品团队，并需要简单的商业分析。数据科学家感到很无聊，所学技能根本用不上。</li></ul><p>问题在于数据产品之间缺少沟通并且没有目标。单独割裂的职位划分与工作协同，将影响目标的推进。</p><blockquote><p>将来会不会诞生一个职业：数据全栈工程师 =&gt; 数据产品思维 + 机器学习技能 + 大数据工程化技能 + 数据前端可视化技能</p></blockquote><h2 id="要做些什么"><a href="#要做些什么" class="headerlink" title="要做些什么"></a>要做些什么</h2><h3 id="理解语境"><a href="#理解语境" class="headerlink" title="理解语境"></a>理解语境</h3><ul><li>找准能从机器学习中受益的区域</li><li>与其他相关人员讨论机器学习能做什么、不能做什么</li><li>让每个人都了解商业策略、风险和目标</li><li>明确目前公司有什么类型的数据</li><li>对任务制定合适的框架</li><li>了解操作限制</li><li>提前确定可能的道德风险，例如你的成果有可能被滥用、或被用于宣传</li><li>确定潜在的偏见和潜在的负面反馈</li></ul><h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><ul><li>制作能收集更多不同数据的计划</li><li>将不同来源的数据汇总</li><li>处理缺失的或被污染的数据</li><li>数据可视化</li><li>建立合适的训练集、验证集和测试集</li></ul><h3 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h3><ul><li>选择使用哪个模型</li><li>将资源模型纳入约束条件（即最终模型需要在顶尖设备运行，内存少、延长时间长等等）</li><li>选择超参数（包括架构、损失函数、优化器）</li><li>训练模型，并进行debug。其中包括调参、查看损失函数、训练错误、验证错误是否有改变、监测模型数据、确定错误来源、改变数据清洗和处理的方式、改变数据增强方式、添加更多数据、尝试不同模型、是否过度拟合。</li></ul><h3 id="模型生成"><a href="#模型生成" class="headerlink" title="模型生成"></a>模型生成</h3><ul><li>创建一个API或网页app</li><li>将模型输出成想要的格式</li><li>计划模型多久需要重新训练一次并更新数据</li></ul><h3 id="监测"><a href="#监测" class="headerlink" title="监测"></a>监测</h3><ul><li>追踪模型性能</li><li>监测输入数据，确定数据是否会随时间使得模型失效</li><li>与其他人员交流结果</li><li>制定计划，如何监测和应对意外结果</li></ul><h2 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h2><h3 id="处理数据格式、不兼容和报错"><a href="#处理数据格式、不兼容和报错" class="headerlink" title="处理数据格式、不兼容和报错"></a>处理数据格式、不兼容和报错</h3><p>处理数据的不一致和报错经常是混乱费力的过程。人们有时会将机器学习和数据科学分开，因为对机器学习来说，有时会直接用清洗过的数据进行训练。然而在我的经验中，数据集清洗和训练模型是相关的：我经常会在训练模型的时候发现问题，只能改变输入数据的预处理方法。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;明确工作问题&lt;/strong&gt;、收集并清洗数据、搭建模型、得出结果并&lt;strong&gt;监测变化&lt;/strong&gt;，这些过程通常会以不同形式相互连接，很难单独拿出来作为研究对象。&lt;/p&gt;
&lt;h2 id=&quot;当机器学习项目失败时&quot;&gt;&lt;a href=&quot;#当机器学习项目
      
    
    </summary>
    
      <category term="ML" scheme="/categories/ML/"/>
    
    
  </entry>
  
  <entry>
    <title>试爱neo4j</title>
    <link href="/2019/01/31/%E8%AF%95%E7%88%B1neo4j/"/>
    <id>/2019/01/31/试爱neo4j/</id>
    <published>2019-01-31T01:35:23.000Z</published>
    <updated>2019-01-31T01:45:14.059Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-导入demo数据"><a href="#1-导入demo数据" class="headerlink" title="1. 导入demo数据"></a>1. 导入demo数据</h2><h3 id="load-csv方式（适合热更新，无需停服务）"><a href="#load-csv方式（适合热更新，无需停服务）" class="headerlink" title="load csv方式（适合热更新，无需停服务）"></a>load csv方式（适合热更新，无需停服务）</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">// demo数据的导入例子</span><br><span class="line"></span><br><span class="line"><span class="keyword">LOAD</span> CSV <span class="keyword">WITH</span> HEADERS <span class="keyword">FROM</span> <span class="string">"file:///RetailRecommendationsDemoDataProduct.csv"</span> <span class="keyword">AS</span> <span class="keyword">row</span></span><br><span class="line"><span class="keyword">MERGE</span> (parent_category:<span class="keyword">Category</span> &#123;<span class="keyword">name</span>: row.parent_category&#125;)</span><br><span class="line"><span class="keyword">MERGE</span> (<span class="keyword">category</span>:<span class="keyword">Category</span> &#123;<span class="keyword">name</span>: row.category&#125;)</span><br><span class="line"><span class="keyword">MERGE</span> (<span class="keyword">category</span>)-[:PARENT_CATEGORY]-&gt;(parent_category)</span><br><span class="line"><span class="keyword">MERGE</span> (p:Product &#123;sku: toString(row.sku)&#125;)</span><br><span class="line"><span class="keyword">SET</span> p.name  = row.name,</span><br><span class="line">    p.price = toFloat(row.price)</span><br><span class="line"><span class="keyword">MERGE</span> (p)-[:IN_CATEGORY]-&gt;(<span class="keyword">category</span>)</span><br><span class="line"><span class="keyword">MERGE</span> (d:Designer &#123;<span class="keyword">name</span>: row.designer&#125;)</span><br><span class="line"><span class="keyword">MERGE</span> (p)-[:DESIGNED_BY]-(d)</span><br><span class="line"><span class="keyword">RETURN</span> *;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">// 智子推荐增量数据导入例子</span><br><span class="line"></span><br><span class="line"><span class="keyword">LOAD</span> CSV <span class="keyword">WITH</span> HEADERS <span class="keyword">FROM</span> <span class="string">"file:///sales_xxxxxxxx.csv"</span> <span class="keyword">AS</span> <span class="keyword">row</span></span><br><span class="line"><span class="keyword">MERGE</span> (buyer:<span class="keyword">User</span> &#123;buyer_nick: row.buyer_nick&#125;)</span><br><span class="line"><span class="keyword">MERGE</span> (plat:Platform &#123;platform_code: row.platform_code&#125;)</span><br><span class="line"><span class="keyword">SET</span> plat.platform_name = row.platform_name</span><br><span class="line"><span class="keyword">MERGE</span> (brand:Brand &#123;brand_id: row.brand_id&#125;)</span><br><span class="line"><span class="keyword">SET</span> brand.brand_name = row.brand_name</span><br><span class="line"><span class="keyword">MERGE</span> (<span class="keyword">store</span>:<span class="keyword">Store</span> &#123;store_id: row.store_id&#125;)</span><br><span class="line"><span class="keyword">SET</span> store.store_name = row.store_name</span><br><span class="line"><span class="keyword">MERGE</span> (c:<span class="keyword">Category</span> &#123;category_code: row.category_code&#125;)</span><br><span class="line"><span class="keyword">SET</span> c.category_code = row.category_code</span><br><span class="line"><span class="keyword">MERGE</span> (s:Season &#123;season: row.season&#125;)</span><br><span class="line"><span class="keyword">SET</span> s.season_name = row.season_name</span><br><span class="line"><span class="keyword">MERGE</span> (p:Product &#123;platform_code: row.platform_code&#125;)</span><br><span class="line"><span class="keyword">SET</span> p.product_name = row.product_name</span><br><span class="line"></span><br><span class="line"><span class="keyword">MERGE</span> (p)-[:IN_CATEGORY]-&gt;(c)</span><br><span class="line"><span class="keyword">MERGE</span> (p)-[:IN_SEASON]-&gt;(s)</span><br><span class="line"><span class="keyword">MERGE</span> (p)-[:IN_BRAND]-(brand)</span><br><span class="line"><span class="keyword">MERGE</span> (p)-[:IN_PLATFORM]-&gt;(plat)</span><br><span class="line"><span class="keyword">MERGE</span> (p)-[:IN_STORE]-(<span class="keyword">store</span>)</span><br><span class="line"><span class="keyword">MERGE</span> (buyer)-[:BUY]-(p)</span><br><span class="line"><span class="keyword">MERGE</span> (p)-[:BE_BOUGHT]-(buyer)</span><br><span class="line"></span><br><span class="line"><span class="keyword">RETURN</span> *;</span><br></pre></td></tr></table></figure><p>几个值得注意的地方：</p><ol><li>load csv的本地path是相对于import路径的（当然也可以传入网络文件路径），所以需要把数据文件复制到对应目录中，例如目录（macOS）：<code>/Users/alithink/Library/Application\ Support/Neo4j\ Desktop/Application/neo4jDatabases/database-4a70fe04-c5a9-41f4-9b8e-5e5c52e283dd/installation-3.5.0/import</code></li><li>load csv的速度还是太慢了，不适合较大存量数据的导入场景。但优势在于导入无需停服务，无需重置数据库，适合增量数据的更新导入场景。</li></ol><h3 id="neo4j-import方式（需要停服务，重建数据库，速度快如闪电）"><a href="#neo4j-import方式（需要停服务，重建数据库，速度快如闪电）" class="headerlink" title="neo4j-import方式（需要停服务，重建数据库，速度快如闪电）"></a>neo4j-import方式（需要停服务，重建数据库，速度快如闪电）</h3><blockquote><p>智子neo4j数据整理: 在内网环境构建了数据预处理程序。</p></blockquote><h4 id="首先将数据处理为import可以接受的数据格式"><a href="#首先将数据处理为import可以接受的数据格式" class="headerlink" title="首先将数据处理为import可以接受的数据格式"></a>首先将数据处理为import可以接受的数据格式</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># node数据整理</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 筛选数据维度</span></span><br><span class="line">season_df = sale_df[[<span class="string">"season"</span>, <span class="string">"season_name"</span>]]</span><br><span class="line"><span class="comment"># 打标签</span></span><br><span class="line">season_df[<span class="string">':LABEL'</span>] = <span class="string">'Season'</span></span><br><span class="line"><span class="comment"># 避免id出现冲突（neo4j id命名空间不许存在重复项）</span></span><br><span class="line">season_df[<span class="string">"season"</span>] =[ <span class="string">'season_%i'</span> % i <span class="keyword">for</span> i <span class="keyword">in</span> season_df[<span class="string">"season"</span>]]</span><br><span class="line"><span class="comment"># 指定id列名</span></span><br><span class="line">season_df = season_df.rename(columns=&#123;<span class="string">"season"</span>: <span class="string">"season:ID"</span>&#125;)</span><br><span class="line"><span class="comment"># 去重</span></span><br><span class="line">season_df = season_df.drop_duplicates()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># relation数据整理</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 筛选数据维度</span></span><br><span class="line">product_user_df = sale_df[[<span class="string">'product_code'</span>,<span class="string">'buyer_nick'</span>, <span class="string">'quantity'</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去除空格（异常数据处理，neo4j会对空格默认忽略）</span></span><br><span class="line">product_user_df[<span class="string">'buyer_nick'</span>] = product_user_df[<span class="string">'buyer_nick'</span>].map(str.strip)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚合数据</span></span><br><span class="line">product_user_df = product_user_df.groupby([<span class="string">'product_code'</span>, <span class="string">'buyer_nick'</span>]) \</span><br><span class="line">    .agg(&#123;</span><br><span class="line">        <span class="string">'quantity'</span>: <span class="string">'sum'</span></span><br><span class="line">    &#125;) \</span><br><span class="line">    .reset_index()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打标签</span></span><br><span class="line">product_user_df[<span class="string">':TYPE'</span>] = <span class="string">'BE_BOUGHT'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定start end 以及releation属性</span></span><br><span class="line">product_user_df = product_user_df.rename(columns=&#123;</span><br><span class="line">    <span class="string">"product_code"</span>: <span class="string">":START_ID"</span>,</span><br><span class="line">    <span class="string">"quantity"</span>: <span class="string">"buy_num"</span>,</span><br><span class="line">    <span class="string">"buyer_nick"</span>: <span class="string">":END_ID"</span></span><br><span class="line">                                                         &#125;)</span><br><span class="line"></span><br><span class="line">product_user_df = product_user_df[[<span class="string">':START_ID'</span>,<span class="string">'buy_num'</span>, <span class="string">':END_ID'</span>, <span class="string">':TYPE'</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 排除空数据</span></span><br><span class="line">product_user_df = product_user_df.dropna()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据导出</span></span><br><span class="line">season_df.to_csv(<span class="string">'neo4j/season.csv'</span>,index=<span class="keyword">False</span>)</span><br><span class="line">user_product_df.to_csv(<span class="string">'neo4j/user_product.csv'</span>,index=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><h4 id="import导入操作"><a href="#import导入操作" class="headerlink" title="import导入操作"></a>import导入操作</h4><p>检查项：</p><ul><li>首先将数据文件cp到neo4j主目录下的import文件夹下</li><li>确认neo4j服务已停止</li><li>删除neo4j主目录data/databases/graph.db</li></ul><p>执行如下命令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/neo4j-admin import --nodes import/brand.csv --nodes import/buyer.csv --nodes import/category.csv --nodes import/platform.csv --nodes import/product.csv --nodes import/season.csv --nodes import/store.csv --relationships import/product_brand.csv --relationships import/product_category.csv --relationships import/product_platform.csv --relationships import/product_season.csv --relationships import/product_store.csv --relationships import/user_product.csv --relationships import/product_user.csv --delimiter <span class="string">","</span> --array-delimiter <span class="string">"|"</span> --quote <span class="string">"'"</span></span><br></pre></td></tr></table></figure></p><h3 id="几种导入方式的对比"><a href="#几种导入方式的对比" class="headerlink" title="几种导入方式的对比"></a>几种导入方式的对比</h3><p><img src="https://i.loli.net/2019/01/31/5c5252a9d550f.jpg" alt=""></p><h4 id="load-csv速度参考"><a href="#load-csv速度参考" class="headerlink" title="load csv速度参考"></a>load csv速度参考</h4><p><img src="https://i.loli.net/2019/01/31/5c5252a9a7162.jpg" alt=""></p><h4 id="neo4j-import速度参考"><a href="#neo4j-import速度参考" class="headerlink" title="neo4j-import速度参考"></a>neo4j-import速度参考</h4><p><img src="https://i.loli.net/2019/01/31/5c5252a9a6e7f.jpg" alt=""></p><h2 id="2-查看数据"><a href="#2-查看数据" class="headerlink" title="2. 查看数据"></a>2. 查看数据</h2><h3 id="启动neo4j服务"><a href="#启动neo4j服务" class="headerlink" title="启动neo4j服务"></a>启动neo4j服务</h3><p><code>$NEO4J_HOME/bin/neo4j console</code></p><p>几个值得注意的地方：</p><ul><li>外网访问(conf/neo4j.conf)：<code>dbms.connector.http.listen_address=0.0.0.0:7474</code></li><li>query日志需要单独配置打开。</li><li>默认用户名密码neo4j/neo4j(产出db文件不会重置用户名密码)</li></ul><h3 id="查看数据结构"><a href="#查看数据结构" class="headerlink" title="查看数据结构"></a>查看数据结构</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">call</span> db.schema()</span><br></pre></td></tr></table></figure><p>demo结果如下：<br><img src="https://i.loli.net/2019/01/31/5c5252a9aa4bb.png" alt="屏幕快照 2019-01-24 上午11.23.41"></p><p>智子推荐db结果如下（不知道为啥有的球中间的文字没显示，感觉neo4j的前端还是有bug）：<br><img src="https://i.loli.net/2019/01/31/5c5252a9ac7f5.png" alt="屏幕快照 2019-01-26 下午12.14.44"></p><h2 id="推荐尝鲜"><a href="#推荐尝鲜" class="headerlink" title="推荐尝鲜"></a>推荐尝鲜</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 智子关联规则推荐</span><br><span class="line"></span><br><span class="line">match (s_product:Product &#123;product_code: "IG6431"&#125;)-[:BE_BOUGHT]-&gt;(s_user:User)&lt;-[:BE_BOUGHT]-(rec:Product)</span><br><span class="line">return rec.product_code, count(s_user) as `Score` </span><br><span class="line">order by count(s_user) desc limit 1000</span><br></pre></td></tr></table></figure><p>结果如下：<br><img src="https://i.loli.net/2019/01/31/5c5252a9caa21.png" alt="屏幕快照 2019-01-26 下午12.18.51"></p><h2 id="tips"><a href="#tips" class="headerlink" title="tips"></a>tips</h2><ul><li>换行输入shift+回车</li><li>切换到换行模式，command+回车执行语句</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://mp.weixin.qq.com/s?__biz=MzU0NzAxNTYyMQ==&amp;mid=2247483826&amp;idx=1&amp;sn=0b7fb426830c4b8dd63cd8ce29bf3d14&amp;chksm=fb559f18cc22160ea95cb0b9e3007c0c3570c2da606685c05353f66d90059efe2fd7d014d0d4&amp;token=1799051627&amp;lang=zh_CN#rd" target="_blank" rel="noopener">知识图谱 | 基于neo4j的即时推荐引擎</a></li><li><a href="https://www.linkedin.com/pulse/simplifying-market-basket-analysis-using-graph-neo4j-achal-shantharam" target="_blank" rel="noopener">Simplifying Market Basket Analysis using a Graph Database (Neo4j)</a></li><li><a href="https://blog.csdn.net/xingxiupaioxue/article/details/71747284" target="_blank" rel="noopener">如何将大规模数据导入Neo4j</a></li><li><a href="https://neo4j.com/docs/operations-manual/current/tutorial/import-tool/" target="_blank" rel="noopener">官方导入实例</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-导入demo数据&quot;&gt;&lt;a href=&quot;#1-导入demo数据&quot; class=&quot;headerlink&quot; title=&quot;1. 导入demo数据&quot;&gt;&lt;/a&gt;1. 导入demo数据&lt;/h2&gt;&lt;h3 id=&quot;load-csv方式（适合热更新，无需停服务）&quot;&gt;&lt;a hre
      
    
    </summary>
    
      <category term="ML" scheme="/categories/ML/"/>
    
    
  </entry>
  
  <entry>
    <title>正确使用交叉验证</title>
    <link href="/2018/12/25/%E6%AD%A3%E7%A1%AE%E4%BD%BF%E7%94%A8%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/"/>
    <id>/2018/12/25/正确使用交叉验证/</id>
    <published>2018-12-25T10:48:33.000Z</published>
    <updated>2018-12-25T10:49:44.020Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>引子：在封装cell预测模块的交叉验证功能时想到，到底是应该直接把交叉验证中效果较好的模型持久化下来用于预测？还是像现在这样子，用全部数据集重新训练一个模型用于后期的预测？</p></blockquote><h2 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h2><p>You do cross-validation when you want to do any of these two things:</p><ul><li>Model Selection</li><li>Error Estimation of a Model</li></ul><p>Model selection can come in different scenarios:</p><p>Selecting one algorithm vs others for a particular problem/dataset<br>Selecting hyper-parameters of a particular algorithm for a particular problem/dataset<br>(please notice that if you are both selecting an algorithm - better to call it model - and also doing hyper-parameters search, you need to do Nested Cross Validation . Is Nested-CV really necessary?)</p><p>Cross-validation ensures up to some degree that the error estimate is the closest possible as generalization error for that model (although this is very hard to approximate). When observing the average error among folds you can have a good projection of the expected error for a model built on the full dataset. Also is importance to observe the variance of the prediction, this is, how much the error varies from fold to fold. If the variation is too high (considerably different values) then the model will tend to be unstable. Bootstrapping is the other method providing good approximation in this sense. I suggest to read carefully the section 7 on “Elements of Statistical Learning” Book, freely available at: <a href="https://web.stanford.edu/~hastie/ElemStatLearn//printings/ESLII_print12.pdf" target="_blank" rel="noopener">ELS-Standford</a></p><p>As it has been mentioned before you must not take the built model in none of the folds. Instead, you have to rebuild the model with the full dataset (the one that was split into folds). If you have a separated test set, you can use it to try this final model, obtaining a similar (and must surely higher) error than the one obtained by CV. You should, however, rely on the estimated error given by the CV procedure.</p><p>After performing CV with different models (algorithm combination, etc) chose the one that performed better regarding error and its variance among folds. You will need to rebuild the model with the whole dataset. Here comes a common confusion in terms: we commongly refer to model selection, thinking that the model is the ready-to-predict model built on data, but in this case it refers to the combination of algorithm+preprocesing procedures you apply. So, to obtain the actual model you need for making predictions/classification you need to build it using the winner combination on the whole dataset.</p><p>Last thing to note is that if you are applying any kind of preprocessing the uses the class information (feature selection, LDA dimensionality reduction, etc) this must be performed in every fold, and not previously on data. This is a critical aspect. Should do the same thing if you are applying preprocessing methods that involve direct information of data (PCA, normalization, standardization, etc). You can, however, apply preprocessing that is not depend from data (deleting a variable following expert opinion, but this is kinda obvious). This video can help you in that direction: <a href="https://www.youtube.com/watch?v=S06JpVoNaA0" target="_blank" rel="noopener">CV the right and the wrong way</a></p><p>Here, a final nice explanation regarding the subject: <a href="https://stats.stackexchange.com/questions/2306/feature-selection-for-final-model-when-performing-cross-validation-in-machine" target="_blank" rel="noopener">CV and model selection</a></p><h2 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h2><ol><li>在什么时候需要使用交叉验证：<ul><li>做模型选择的时候</li><li>需要评估模型误差的时候</li></ul></li><li>做模型选择又分两种：<ul><li>算法选择 - 普通cv</li><li>算法超参选择 - 格搜索等针对超参优化</li></ul></li><li>交叉验证能看出什么：<ul><li>较为接近的衡量一个模型的误差表现</li><li>观察方差，判断模型的稳定性</li></ul></li></ol><p><strong>重点来了：不要将交叉验证中效果最好的模型直接作最终预测使用，而应该用全部数据集重新训练一个模型。</strong>（看来没用错，这也是探索这一波的起因 =。=）</p><h2 id="意外收获：重大附加发现"><a href="#意外收获：重大附加发现" class="headerlink" title="意外收获：重大附加发现"></a>意外收获：重大附加发现</h2><p>如果数据集需要进行下来动作，请在交叉验证切分完数据集后进行：</p><ul><li>标准化、MinMax等结合数据规模的数据预处理手段。</li><li>特征选择、LDA等结合类标的相关处理。</li></ul><p>但是cross_val_score如何对切分后的数据集做处理呢？<br>官方文档给出了答案：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline</span><br><span class="line">clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=<span class="number">1</span>))</span><br><span class="line">cross_val_score(clf, iris.data, iris.target, cv=cv)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;引子：在封装cell预测模块的交叉验证功能时想到，到底是应该直接把交叉验证中效果较好的模型持久化下来用于预测？还是像现在这样子，用全部数据集重新训练一个模型用于后期的预测？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;原文&quot;&gt;&lt;a href
      
    
    </summary>
    
      <category term="ML" scheme="/categories/ML/"/>
    
    
  </entry>
  
  <entry>
    <title>Gratitude</title>
    <link href="/2018/12/21/Gratitude/"/>
    <id>/2018/12/21/Gratitude/</id>
    <published>2018-12-21T09:57:26.000Z</published>
    <updated>2018-12-26T03:44:33.388Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>写这篇文章的时候，正饱受牙痛之苦。。<br>珍惜你的牙齿，守住她们就是守住你未来的幸福。</p></blockquote><p><img src="https://i.loli.net/2018/12/26/5c22f9166ee33.png" alt="Gratitude"></p><h2 id="一、引子"><a href="#一、引子" class="headerlink" title="一、引子"></a>一、引子</h2><p>我们来到这个世上，到底追求什么才是最重要的？Tal坚定地认为：幸福感是衡量人生的唯一标准，是所有目标的最终目标。（Tal博士被誉为”最受欢迎讲师”和”人生导师”）。</p><p>多年前的一段心灵迷茫期，让我偶遇了Tal这位人生导师以及他的哈佛幸福课（给个背影吧，正面会不会侵犯肖像权）。<br><img src="https://i.loli.net/2018/12/21/5c1cb92e67d9c.jpg" alt="111"></p><p>视频传送门：<a href="http://open.163.com/special/positivepsychology/" target="_blank" rel="noopener">http://open.163.com/special/positivepsychology/</a></p><p>自从听了Tal的课，就有将其中的「感恩练习」做个App的打算。但惊慌怪兽迟迟没有醒来，此事也一拖再拖。直到今年的感恩节前夕，她终于突然跳了出来，提醒我「您有一个kpi尚未完成，请立刻行动起来，deadline不远了」。于是经过一段时间的折腾与回忆（毕竟已经离开iOS圈子有段时间了），这个App就这么诞生了。撒花ing</p><h2 id="二、应用简介"><a href="#二、应用简介" class="headerlink" title="二、应用简介"></a>二、应用简介</h2><p>应用传送门（iOS safari打开）：<a href="http://tinyurl.com/y7zw4bns" target="_blank" rel="noopener">http://tinyurl.com/y7zw4bns</a></p><p><img src="https://i.loli.net/2018/12/21/5c1cba5940f19.jpg" alt="gratitude"></p><h3 id="产品逻辑"><a href="#产品逻辑" class="headerlink" title="产品逻辑"></a>产品逻辑</h3><p>只要带上感恩的眼镜去观察生活，将生活中已经习惯的「理所当然」重新思考，就会发现生活中其实充满着值得感恩的事情。美味的食物、父母与妻子对家庭的付出、孩子的点滴成长、朋友同事间的帮助支持等等都值得去感恩。就像Tal课程中举例说明的那样，持久幸福的模型其实是螺旋上升的形态，是由一个个的小幸福累积而成。偶然的惊喜，幸福感消退的也会特别快。</p><p>「Gratitude」每日希望我们记录下三件值得感恩的小事。起初发现三件值得感恩的事可能会觉得有点难，但坚持下来经过一段时间的练习，它会潜移默化地改变一个人观察事物的视角。慢慢地，随着一点点小幸福的积累，它将帮助我们进入螺旋上升的幸福模型中。</p><p>同时「Gratitude」增加了分享功能，对于那些并不那么隐私的感恩话题，完全可以分享出来（有些事情用文字来表达，可能比当面开口更容易一些）。将自己整理的内容分享给对方，对方接收到你的感恩，其实也是某种意义上幸福的传递，彼此之间的情感也在升华。</p><h3 id="产品功能"><a href="#产品功能" class="headerlink" title="产品功能"></a>产品功能</h3><ul><li>主页面：每日三次感恩记录模块，保存后可随时更新分享。</li><li>历史感恩列表：点击✉️进入历史感恩列表模块，在这里可以回顾你留下的所有感恩记录。</li><li>感恩编辑页：在这里可以对已生成的感恩记录进行编辑修改，与主页面功能类似。在历史感恩列表中点击任意感恩记录即可进入。</li><li>分享页：分享页专门制作了两个主题，也是为了鼓励大胆分享出我们的感恩记录，让幸福传递。（白色主题，借鉴了我最喜欢的移动端文字编辑类APP锤子标签，希望大家喜欢~，并希望罗老师能坚持下去）</li></ul><h2 id="三、得到"><a href="#三、得到" class="headerlink" title="三、得到"></a>三、得到</h2><p>每年一个App的小flag，逼自己挤出些时间回顾下移动端开发的相关知识，虽然已经转战ML，但移动端的skill也不能落下哈。（希望能把这个flag继续坚持下去吧💪）</p><p>最后也希望这个小小的App能够帮助到大家，Enjoy it🎉</p><p><strong>ps:应用限免至2019年1月9日，喜欢的老铁，好评走一波哈~</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;写这篇文章的时候，正饱受牙痛之苦。。&lt;br&gt;珍惜你的牙齿，守住她们就是守住你未来的幸福。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2018/12/26/5c22f9166ee33.png&quot;
      
    
    </summary>
    
      <category term="个人作品" scheme="/categories/%E4%B8%AA%E4%BA%BA%E4%BD%9C%E5%93%81/"/>
    
    
  </entry>
  
  <entry>
    <title>《人工智能转型手册》读后感</title>
    <link href="/2018/12/17/%E3%80%8A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%BD%AC%E5%9E%8B%E6%89%8B%E5%86%8C%E3%80%8B%E8%AF%BB%E5%90%8E%E6%84%9F/"/>
    <id>/2018/12/17/《人工智能转型手册》读后感/</id>
    <published>2018-12-17T07:07:08.000Z</published>
    <updated>2018-12-17T07:59:24.518Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>传送门：<a href="https://landing.ai/ai-transformation-playbook/" target="_blank" rel="noopener">原文链接</a> <a href="https://mp.weixin.qq.com/s/WRgh7KRFYEzehK3zkzTWeA" target="_blank" rel="noopener">中文翻译</a></p></blockquote><h2 id="看完记住了什么"><a href="#看完记住了什么" class="headerlink" title="看完记住了什么"></a>看完记住了什么</h2><ul><li>企业进行AI赋能，更高效的策略是要先行动起来，用小范围的实践碰撞出AI的落地点。</li><li>在初期AI实践项目的选择上，要选择那些好衡量、好落地、容易出效果的点。<ul><li>用初期实践项目取得的成果，作为AI赋能至更多业务场景的背书。</li><li>增加进一步结合实践的信心。</li></ul></li><li>企业做AI要结合自身业务行业背景，结合自身业务经验知识储备优势，发展出适合自身所处行业背景下的「特色应用」，而非通用AI应用场景（这部分交由Google等大公司来搞吧，自己来做，投入产出比过低）。</li><li>识别内外团队能力边界，更好的利用外部团队的研究成果，加速企业内部AI项目的落地。</li><li>自上而下的认知，企业不同层级对AI赋能边界的认知，避开不适合AI来做的点，聚焦在更适合来探索实践的方向。</li><li>储备更有意义的数据。AI团队的更早加入，随着数据模型探索的开展，将有利于公司数据团队发掘储备更多利于未来业务开展的核心数据维度。而基于AI的特点，数据储备的越早，AI模型的价值就利于更早的发挥出来，更快的落地，正向循环，以致建立商业优势的护城河。</li><li>有更多的企业实践成功案例，也为业务AI团队的招聘建立优势。</li></ul><h2 id="韩都这边的实践"><a href="#韩都这边的实践" class="headerlink" title="韩都这边的实践"></a>韩都这边的实践</h2><ul><li>初期结合贯穿电商运营的核心节拍器销量预测进行了一波数据探索，根据数据模型探索结果，最终确定以大活动销量预测作为初期实践项目。<ul><li>电商以平台活动脉动的运营节奏，使得活动销量预测对电商运营来说意义颇重。</li><li>企业自身也会进行业务专家的活动销量预测，有了人工预测结果，便于模型预测效果的业务衡量。初期模型目标定为达到业务专家的预测水平。</li><li>目前实践的结果，基本与业务专家预测效果持平，持续优化中。</li></ul></li><li>其它方向的应用：<ul><li>封装了AI接口平台「矩阵」，向各业务系统输出AI能力。</li><li>商品推荐：结合商品销售数据与商品元素属性，进行关联规则、协同过滤以及货品相似性推荐。结合企业内部的BI系统进行发布落地。</li><li>水滴相关性探索平台：将AI探索过程中发掘的数据规律进行集中展示的地方，给运营人员提供业务分析的新视角。</li></ul></li><li>与外部团队的合作：<ul><li>结合阿里nlp的评价分析应用。</li><li>结合百度识图的图片相似度应用，货品图片查重，相似竞品查找等。</li></ul></li><li>数据储备：<ul><li>韩都核心内部系统全部自研，内部系统数据打通汇流于HBI（韩都商业智能系统）。AI模型所需数据基本可从HBI一点获取，数据获取成本低，数据质量高。</li><li>在早期的模型探索中，也发掘反哺出一些有意义的数据特征维度，在HBI中进行沉淀，蓄势待发。</li></ul></li><li>人员招聘。。说多了都是泪。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;传送门：&lt;a href=&quot;https://landing.ai/ai-transformation-playbook/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原文链接&lt;/a&gt; &lt;a href=&quot;https://mp.wei
      
    
    </summary>
    
      <category term="ML" scheme="/categories/ML/"/>
    
    
  </entry>
  
  <entry>
    <title>智子airflow配置指南</title>
    <link href="/2018/09/21/%E6%99%BA%E5%AD%90airflow%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/"/>
    <id>/2018/09/21/智子airflow配置指南/</id>
    <published>2018-09-21T06:47:26.000Z</published>
    <updated>2018-11-22T06:50:33.159Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装python3"><a href="#安装python3" class="headerlink" title="安装python3"></a>安装python3</h2><blockquote><p><a href="https://www.yuzhi100.com/tutorial/centos/centos-anzhuang-python36" target="_blank" rel="noopener">https://www.yuzhi100.com/tutorial/centos/centos-anzhuang-python36</a></p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#安装EPEL依赖</span><br><span class="line">sudo yum install epel-release</span><br><span class="line"></span><br><span class="line">#安装IUS软件源</span><br><span class="line">sudo yum install https://centos7.iuscommunity.org/ius-release.rpm</span><br><span class="line"></span><br><span class="line">sudo yum install python36u</span><br><span class="line">sudo ln -s /bin/python3.6 /bin/python3</span><br><span class="line"></span><br><span class="line">sudo yum install python36u-pip</span><br><span class="line">sudo ln -s /bin/pip3.6 /bin/pip3</span><br></pre></td></tr></table></figure><h2 id="安装airflow"><a href="#安装airflow" class="headerlink" title="安装airflow"></a>安装airflow</h2><h3 id="1-添加环境变量"><a href="#1-添加环境变量" class="headerlink" title="1. 添加环境变量"></a>1. 添加环境变量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export SLUGIFY_USES_TEXT_UNIDECODE=yes</span><br></pre></td></tr></table></figure><h3 id="2-环境安装"><a href="#2-环境安装" class="headerlink" title="2. 环境安装"></a>2. 环境安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install python36u-devel.x86_64</span><br><span class="line"></span><br><span class="line">sudo yum install mysql-community-devel.x86_64</span><br><span class="line"></span><br><span class="line"># sasl/sasl.h: No such file or directory</span><br><span class="line">yum install gcc-c++ cyrus-sasl-devel.x86_64</span><br></pre></td></tr></table></figure><h3 id="3-元数据库配置（mysql）"><a href="#3-元数据库配置（mysql）" class="headerlink" title="3. 元数据库配置（mysql）"></a>3. 元数据库配置（mysql）</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- xxxx</span><br><span class="line"></span><br><span class="line">CREATE DATABASE airflow;</span><br><span class="line"></span><br><span class="line">GRANT all privileges on airflow.* TO &apos;root&apos;@&apos;localhost&apos;  IDENTIFIED BY &apos;xxxx&apos;;</span><br><span class="line"></span><br><span class="line">ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;xxxx&apos; PASSWORD EXPIRE NEVER;</span><br><span class="line"></span><br><span class="line">ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED WITH mysql_native_password BY &apos;xxxx&apos;;</span><br></pre></td></tr></table></figure><h3 id="4-AIRFLOW-HOME-airflow-cfg文件配置"><a href="#4-AIRFLOW-HOME-airflow-cfg文件配置" class="headerlink" title="4. \$AIRFLOW_HOME/airflow.cfg文件配置"></a>4. \$AIRFLOW_HOME/airflow.cfg文件配置</h3><blockquote><p>将AIRFLOW_HOME加入环境变量</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sql_alchemy_conn = mysql://root:xxxx@localhost:3306/airflow</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">from cryptography.fernet import Fernet</span><br><span class="line"></span><br><span class="line">fernet_key= Fernet.generate_key()</span><br><span class="line">print(fernet_key) # your fernet_key, keep it in secured place!</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 安装加密模块</span><br><span class="line">pip install flask-bcrypt</span><br></pre></td></tr></table></figure><blockquote><p>暴露端口5001</p></blockquote><h3 id="5-配置用户"><a href="#5-配置用户" class="headerlink" title="5. 配置用户"></a>5. 配置用户</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">import airflow</span><br><span class="line">from airflow import models, settings</span><br><span class="line">from airflow.contrib.auth.backends.password_auth import PasswordUser</span><br><span class="line"></span><br><span class="line">user = PasswordUser(models.User())</span><br><span class="line">user.username = &apos;alithink&apos;</span><br><span class="line">user.email = &apos;xxxx&apos;</span><br><span class="line">user.password = &apos;xxxx&apos;</span><br><span class="line">session = settings.Session()</span><br><span class="line">session.add(user)</span><br><span class="line">session.commit()</span><br><span class="line">session.close()</span><br><span class="line">exit()</span><br></pre></td></tr></table></figure><h2 id="启动airflow"><a href="#启动airflow" class="headerlink" title="启动airflow"></a>启动airflow</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nohup airflow webserver -p 5001 &amp;</span><br><span class="line"></span><br><span class="line"># 每次resetdb后scheduler要重启</span><br><span class="line">nohup airflow scheduler &amp;</span><br></pre></td></tr></table></figure><h2 id="airflow-tips"><a href="#airflow-tips" class="headerlink" title="airflow tips"></a>airflow tips</h2><ul><li>cfg配置改变后要进行重启</li><li>默认utc时间，建议在dag配置的时候进行时区的考量（web ui只支持utc…）</li><li>dag开关置为on之后，如果scheduler已启动，start-date到目前每个执行计划节点的任务都会依次执行。</li><li>可以点击立刻执行，进行手动dag执行。</li><li>每个节点的日志，可以点击对应task，然后查看task instance log</li><li>UTC时间，需要在原本打算设置的时间减8小时</li><li>catch_up: 如果指定的开始时间早于当前时间且catch_up设置为true，那么airflow会把过去‘遗漏’的调度执行一遍</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;安装python3&quot;&gt;&lt;a href=&quot;#安装python3&quot; class=&quot;headerlink&quot; title=&quot;安装python3&quot;&gt;&lt;/a&gt;安装python3&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.yuzhi100
      
    
    </summary>
    
      <category term="airflow" scheme="/categories/airflow/"/>
    
    
  </entry>
  
  <entry>
    <title>智子模型评估与输出</title>
    <link href="/2018/07/12/%E6%99%BA%E5%AD%90%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E8%BE%93%E5%87%BA/"/>
    <id>/2018/07/12/智子模型评估与输出/</id>
    <published>2018-07-12T06:58:21.000Z</published>
    <updated>2018-11-22T07:32:44.247Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.001.jpeg" alt="智子模型评估与输出.001.jpeg"><br><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.002.jpeg" alt="智子模型评估与输出.002.jpeg"><br><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.003.jpeg" alt="智子模型评估与输出.003.jpeg"><br><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.004.jpeg" alt="智子模型评估与输出.004.jpeg"><br><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.005.jpeg" alt="智子模型评估与输出.005.jpeg"><br><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.006.jpeg" alt="智子模型评估与输出.006.jpeg"><br><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.007.jpeg" alt="智子模型评估与输出.007.jpeg"><br><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.008.jpeg" alt="智子模型评估与输出.008.jpeg"><br><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.009.jpeg" alt="智子模型评估与输出.009.jpeg"><br><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.010.jpeg" alt="智子模型评估与输出.010.jpeg"><br><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.011.jpeg" alt="智子模型评估与输出.011.jpeg"><br><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.012.jpeg" alt="智子模型评估与输出.012.jpeg"><br><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.013.jpeg" alt="智子模型评估与输出.013.jpeg"><br><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.014.jpeg" alt="智子模型评估与输出.014.jpeg"><br><img src="http://alithink.com/img/sophon/estimate/智子模型评估与输出.015.jpeg" alt="智子模型评估与输出.015.jpeg"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;http://alithink.com/img/sophon/estimate/智子模型评估与输出.001.jpeg&quot; alt=&quot;智子模型评估与输出.001.jpeg&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://alithink.com/img/soph
      
    
    </summary>
    
      <category term="ML" scheme="/categories/ML/"/>
    
    
  </entry>
  
  <entry>
    <title>智子数据探索</title>
    <link href="/2018/06/11/%E6%99%BA%E5%AD%90%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/"/>
    <id>/2018/06/11/智子数据探索/</id>
    <published>2018-06-11T06:58:09.000Z</published>
    <updated>2018-12-17T06:24:41.805Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://alithink.com/img/sophon/explorer/智子数据探索.001.jpeg" alt="智子数据探索.001.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.002.jpeg" alt="智子数据探索.002.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.003.jpeg" alt="智子数据探索.003.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.004.jpeg" alt="智子数据探索.004.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.005.jpeg" alt="智子数据探索.005.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.006.jpeg" alt="智子数据探索.006.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.007.jpeg" alt="智子数据探索.007.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.008.jpeg" alt="智子数据探索.008.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.009.jpeg" alt="智子数据探索.009.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.010.jpeg" alt="智子数据探索.010.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.011.jpeg" alt="智子数据探索.011.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.012.jpeg" alt="智子数据探索.012.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.013.jpeg" alt="智子数据探索.013.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.014.jpeg" alt="智子数据探索.014.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.015.jpeg" alt="智子数据探索.015.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.016.jpeg" alt="智子数据探索.016.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.017.jpeg" alt="智子数据探索.017.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.018.jpeg" alt="智子数据探索.018.jpeg | left | 747x420"><br><img src="http://alithink.com/img/sophon/explorer/智子数据探索.020.jpeg" alt="智子数据探索.020.jpeg | left | 747x420"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;http://alithink.com/img/sophon/explorer/智子数据探索.001.jpeg&quot; alt=&quot;智子数据探索.001.jpeg | left | 747x420&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://alithink.c
      
    
    </summary>
    
      <category term="ML" scheme="/categories/ML/"/>
    
    
  </entry>
  
  <entry>
    <title>智子环境搭建历程</title>
    <link href="/2018/02/24/%E6%99%BA%E5%AD%90%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%8E%86%E7%A8%8B/"/>
    <id>/2018/02/24/智子环境搭建历程/</id>
    <published>2018-02-24T14:00:27.000Z</published>
    <updated>2018-12-21T09:09:58.180Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>智子 - 韩都衣舍机器学习平台代号😋</p></blockquote><h1 id="一、spark流派"><a href="#一、spark流派" class="headerlink" title="一、spark流派"></a>一、spark流派</h1><h2 id="1-1-hadoop"><a href="#1-1-hadoop" class="headerlink" title="1.1 hadoop"></a>1.1 hadoop</h2><blockquote><p>起初选择使用CDH安装（原因：老环境就用的这个，据说比较稳定），然而在双节点情况下总是出现莫名问题。磕磕绊绊安装好了，实际用起来还是有不少问题（集成环境问题定位好麻烦。。），在尝试几波之后最终选择放弃（期间还麻烦运维妹子重做了系统😂）。想到实际需要的功能并不太多，果断转为人工安装部署。<br>CDH的安装部署过程作为番外放在最后面吧。。。</p></blockquote><h3 id="版本选择"><a href="#版本选择" class="headerlink" title="版本选择"></a>版本选择</h3><p>虽然没有安装CDH，还是选用了CDH版的hadoop2.6。（据说体质较好，比较稳健）</p><h3 id="文章参考"><a href="#文章参考" class="headerlink" title="文章参考"></a>文章参考</h3><p><a href="https://www.jianshu.com/p/1448d1550c8b" target="_blank" rel="noopener">CentOS 7 集群部署 Hadoop 2.7.3</a></p><h3 id="坑位介绍"><a href="#坑位介绍" class="headerlink" title="坑位介绍"></a>坑位介绍</h3><blockquote><p>主要记录自己部署时遇到的主要问题，详细步骤可以参考上面的文章</p></blockquote><h4 id="💩-jps发现竟然木有DataNode"><a href="#💩-jps发现竟然木有DataNode" class="headerlink" title="💩 jps发现竟然木有DataNode"></a>💩 jps发现竟然木有DataNode</h4><blockquote><p>之前用CDH安装过一遍hadoop导致部分目录有内容残留</p></blockquote><ul><li>查看$HADOOP_HOME/etc/hadoop/hdfs-site.xml<ul><li>namenode路径</li><li>datanode路径</li><li>删除对应目录下的所有文件</li></ul></li><li>重新执行namenode -format</li><li>重启hadoop start-all.sh</li></ul><h4 id="💩-各种Permission-denied"><a href="#💩-各种Permission-denied" class="headerlink" title="💩 各种Permission denied"></a>💩 各种Permission denied</h4><ul><li>先查看各路径是否正确赋权给了hadoop用户<ul><li>没有的chown -R hadoop:hadoop 对应路径</li></ul></li><li>当前用户是否已经切换成hadoop用户再执行相关启动命令</li></ul><h4 id="💩-没有SecondaryNode了"><a href="#💩-没有SecondaryNode了" class="headerlink" title="💩 没有SecondaryNode了"></a>💩 没有SecondaryNode了</h4><ul><li>配置$HADOOP_HOME/etc/hadoop/hdfs-site.xml<ul><li>name: dfs.namenode.secondary.http-address</li><li>value: 0.0.0.0:50090</li></ul></li></ul><h2 id="1-2-hive"><a href="#1-2-hive" class="headerlink" title="1.2 hive"></a>1.2 hive</h2><h3 id="版本选择-1"><a href="#版本选择-1" class="headerlink" title="版本选择"></a>版本选择</h3><p>目前最新版：apache-hive-2.3.2-bin</p><h3 id="文章参考-1"><a href="#文章参考-1" class="headerlink" title="文章参考"></a>文章参考</h3><p><a href="http://blog.csdn.net/u014591781/article/details/52895176" target="_blank" rel="noopener">Hadoop2.6下安装Hive</a></p><h3 id="坑位介绍-1"><a href="#坑位介绍-1" class="headerlink" title="坑位介绍"></a>坑位介绍</h3><h4 id="💩-启动时各种缺表"><a href="#💩-启动时各种缺表" class="headerlink" title="💩 启动时各种缺表"></a>💩 启动时各种缺表</h4><ul><li>查看$HIVE_HOME/scripts/metastore/upgrade/mysql/hive-schema-2.3.0.mysql.sql</li><li>用root用户登录至mysql</li><li>创建对应的用户并授权用户（别忘记flush privileges）</li><li>然后执行这个初始化sql</li></ul><h4 id="💩-如何重启hive-metastore"><a href="#💩-如何重启hive-metastore" class="headerlink" title="💩 如何重启hive metastore"></a>💩 如何重启hive metastore</h4><ul><li>ps -ef |grep HiveMetaStore</li><li>kill -TERM pid</li><li>hive –service hiveserver &amp;</li></ul><h2 id="1-3-sqoop"><a href="#1-3-sqoop" class="headerlink" title="1.3 sqoop"></a>1.3 sqoop</h2><h3 id="版本选择-2"><a href="#版本选择-2" class="headerlink" title="版本选择"></a>版本选择</h3><blockquote><p>官网说了诸多sqoop2的好处，最后建议说生产环境不要使用2…</p></blockquote><p>sqoop1最新版：sqoop-1.4.7.bin__hadoop-2.6.0</p><h3 id="文章参考-2"><a href="#文章参考-2" class="headerlink" title="文章参考"></a>文章参考</h3><p><a href="https://www.jianshu.com/p/99301eeedd91" target="_blank" rel="noopener">如何将mysql数据导入Hadoop之Sqoop安装</a></p><h3 id="坑位介绍-2"><a href="#坑位介绍-2" class="headerlink" title="坑位介绍"></a>坑位介绍</h3><h4 id="💩-发现总是Connection-Failure"><a href="#💩-发现总是Connection-Failure" class="headerlink" title="💩 发现总是Connection Failure"></a>💩 发现总是Connection Failure</h4><blockquote><p>mysql场景</p></blockquote><ul><li>检查hadoop集群每台机器与mysql数据源的连通性<ul><li>telnet xx.xx.xx.xx 3306</li><li>不同的话，申请开通权限即可</li></ul></li></ul><h4 id="💩-报出jackson-databind缺少某某方法"><a href="#💩-报出jackson-databind缺少某某方法" class="headerlink" title="💩 报出jackson databind缺少某某方法"></a>💩 报出jackson databind缺少某某方法</h4><ul><li>统一hadoop、hive、sqoop各自lib中jackson的版本</li><li>选择三者中的最高版本即可</li></ul><h4 id="💩-报出hive-version与metastore-version不一致"><a href="#💩-报出hive-version与metastore-version不一致" class="headerlink" title="💩 报出hive version与metastore version不一致"></a>💩 报出hive version与metastore version不一致</h4><ul><li>如果报出hive版本低于metastore版本（跟我一样）<ul><li>关闭版本检查即可</li><li>name: hive.metastore.schema.verification</li><li>value: false</li></ul></li><li>如果报出hive版本高于metastore版本：<ul><li>将元数据库mysql中的对应hive库删除</li><li>用对应版本的script重新初始化元数据表</li><li>同样禁用掉版本检查吧。。</li></ul></li></ul><h4 id="💩-导入hive报错HIVE-CONF-DIR"><a href="#💩-导入hive报错HIVE-CONF-DIR" class="headerlink" title="💩 导入hive报错HIVE_CONF_DIR"></a>💩 导入hive报错HIVE_CONF_DIR</h4><ul><li>.bashrc添加<ul><li>export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$HIVE_HOME/lib/*</li></ul></li><li>source .bashrc</li></ul><h2 id="1-4-spark"><a href="#1-4-spark" class="headerlink" title="1.4 spark"></a>1.4 spark</h2><h3 id="版本选择-3"><a href="#版本选择-3" class="headerlink" title="版本选择"></a>版本选择</h3><blockquote><p>从官网下载的时候，记得选择对应的hadoop版本</p></blockquote><p>spark-2.2.1-bin-hadoop2.6</p><h3 id="文章参考-3"><a href="#文章参考-3" class="headerlink" title="文章参考"></a>文章参考</h3><blockquote><p>过于简单其实也没有参考什么文章。。</p></blockquote><p><a href="http://blog.csdn.net/leon_founder/article/details/78715831" target="_blank" rel="noopener">CentOS 7上安装Spark 2.2单机</a></p><h2 id="1-5-zeppelin"><a href="#1-5-zeppelin" class="headerlink" title="1.5 zeppelin"></a>1.5 zeppelin</h2><h3 id="版本选择-4"><a href="#版本选择-4" class="headerlink" title="版本选择"></a>版本选择</h3><blockquote><p>这里选择了附带所有interpreter的版本</p></blockquote><p>zeppelin最新版：zeppelin-0.7.3-bin-all</p><h3 id="文章参考-4"><a href="#文章参考-4" class="headerlink" title="文章参考"></a>文章参考</h3><p><a href="http://blog.csdn.net/u013013024/article/details/79082503" target="_blank" rel="noopener">CDH安装配置zeppelin-0.7.3以及配置spark查询hive表</a></p><h3 id="坑位介绍-3"><a href="#坑位介绍-3" class="headerlink" title="坑位介绍"></a>坑位介绍</h3><h4 id="💩-报出jackson版本问题"><a href="#💩-报出jackson版本问题" class="headerlink" title="💩 报出jackson版本问题"></a>💩 报出jackson版本问题</h4><ul><li>与之前的问题类似，立刻想到将包统一即可。</li></ul><h4 id="💩-无法初始化SessionHiveMetaStoreClient"><a href="#💩-无法初始化SessionHiveMetaStoreClient" class="headerlink" title="💩 无法初始化SessionHiveMetaStoreClient"></a>💩 无法初始化SessionHiveMetaStoreClient</h4><blockquote><p>由于配置hive之后，需要将hive-site.xml复制HADOOP_CONF_DIR一份，由于zeppelin（支持hive）也需要加载HADOOP_CONF_DIR目录，所以导致无法加载hive元数据，导致异常，此时启动hive的元数据服务在启动zeppelin即可。</p></blockquote><ul><li>拷贝hive-site.xml到$HADOOP_HOME/etc/hadoop</li></ul><h1 id="二、sklearn流派"><a href="#二、sklearn流派" class="headerlink" title="二、sklearn流派"></a>二、sklearn流派</h1><h2 id="2-1-anaconda与jupyter-猪币特"><a href="#2-1-anaconda与jupyter-猪币特" class="headerlink" title="2.1 anaconda与jupyter(猪币特)"></a>2.1 anaconda与jupyter(猪币特)</h2><h3 id="版本选择-5"><a href="#版本选择-5" class="headerlink" title="版本选择"></a>版本选择</h3><p>python3版本：Anaconda3-5.0.1-Linux-x86_64</p><h3 id="文章参考-5"><a href="#文章参考-5" class="headerlink" title="文章参考"></a>文章参考</h3><p><a href="http://blog.csdn.net/c13669463387/article/details/78436691" target="_blank" rel="noopener">在centos7服务器上安装anaconda和jupyter notebook</a></p><p><a href="http://blog.csdn.net/u010694764/article/details/76862854" target="_blank" rel="noopener">远程访问</a></p><h3 id="坑位介绍-4"><a href="#坑位介绍-4" class="headerlink" title="坑位介绍"></a>坑位介绍</h3><blockquote><p>此处应该有掌声，配置太简单了，与spark流派形成鲜明的对比。<br>没啥特别的坑位需要备忘，一切都水到渠成。</p></blockquote><h1 id="三、数据同步策略"><a href="#三、数据同步策略" class="headerlink" title="三、数据同步策略"></a>三、数据同步策略</h1><h2 id="3-1-sqoop同步策略"><a href="#3-1-sqoop同步策略" class="headerlink" title="3.1 sqoop同步策略"></a>3.1 sqoop同步策略</h2><p><img src="https://i.loli.net/2018/12/21/5c1caba11079c.jpg" alt="15194416883439"></p><h3 id="具体sqoop同步示例"><a href="#具体sqoop同步示例" class="headerlink" title="具体sqoop同步示例"></a>具体sqoop同步示例</h3><blockquote><p>sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true –connect jdbc:mysql://xx.xx.xx.xx/数据库名?characterEncoding=utf-8 –username 数据库用户名 –password 数据库密码 –num-mappers 4 –table 源表名 –hive-import –hive-overwrite –hive-table hive表名 –split-by 切分字段（如果有主键默认使用主键）</p></blockquote><h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><ul><li>同步速度真心快。（为什么会这么快呢？3000多万的表15分钟左右）</li><li>hive源数据放置在磁盘中，无需全部加载入内存再进行筛选处理。</li><li>似乎对于源数据库压力不大。</li><li>最终选定该方案。</li></ul><h2 id="3-2-mysql直接拉取csv"><a href="#3-2-mysql直接拉取csv" class="headerlink" title="3.2 mysql直接拉取csv"></a>3.2 mysql直接拉取csv</h2><blockquote><p>在sqoop环境起初搭建不顺利的背景下提出的备选方案。</p></blockquote><h3 id="同步示例"><a href="#同步示例" class="headerlink" title="同步示例"></a>同步示例</h3><blockquote><p>mysql -u数据库用户名 -p数据库密码 -hxx.xx.xx.xx 数据库名 -B -e “select * from `表名`;” | sed ‘s/\t/“,”/g;s/^/“/;s/$/“/;s/\n//g’ &gt; 导出的csv名</p></blockquote><h3 id="效果-1"><a href="#效果-1" class="headerlink" title="效果"></a>效果</h3><ul><li>同步速度较sqoop慢一些。（3000多万的表半个小时左右）</li><li>配置简单，只要网络通即可。</li><li>csv文件较大，直接用pandas读取的话，内存占用会暴涨。<ul><li>不过pandas的大数据集处理速度还是挺快的。</li></ul></li><li>小数据集场景灵活使用。</li></ul><h1 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h1><blockquote><p>经此一役，收获颇多，除了获取知识之外，也总结了几则六字真言，与君共勉。</p></blockquote><ul><li>多备份，少吃亏</li><li>多联想，勤记录</li><li>多虚拟，后物理</li><li>多尝试，不放弃</li></ul><h1 id="五、番外"><a href="#五、番外" class="headerlink" title="五、番外"></a>五、番外</h1><h2 id="CDH篇"><a href="#CDH篇" class="headerlink" title="CDH篇"></a>CDH篇</h2><ul><li>修改hostname hostnamectl set-hostname</li><li>配置hosts</li><li>创建用户hadoop adduser</li><li>passwd</li><li>配置visudo</li><li>reboot</li><li>切换至hadoop用户：<ul><li>ssh免密配置<ul><li>ssh-keygen -t rsa -P “”</li><li>cat id_rsa.pub &gt;&gt; authorized_keys</li><li>多服务器配置同步到master<ul><li>scp id_rsa.pub sophonmaster:/home/hadoop/.ssh/id_rsa.pub.s1</li><li>cat id_rsa.pub.s1 &gt;&gt; authorized_keys</li></ul></li></ul></li></ul></li><li>root用户密码未知，新创建hadoop用户，配置对应密码<ul><li>visudo<ul><li>hadoop ALL=(root)NOPASSWD:ALL</li><li>wheel nopasswd放开</li></ul></li></ul></li><li>消除警告：<ul><li><img src="https://i.loli.net/2018/12/21/5c1caba0b8bb0.jpg" alt="15180588854980"></li><li>echo 0 &gt; /proc/sys/vm/swappiness</li><li>echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</li><li>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</li></ul></li><li>关闭防火墙<ul><li>systemctl stop firewalld</li><li>systemctl disable firewalld</li><li>systemctl status firewalld</li></ul></li><li>关闭SELinux(centos7 默认关闭)<ul><li>/etc/selinux/config</li></ul></li><li>常规CDH安装方式：<ul><li>将cloudera-manager.repo文件拷贝到所有节点的/etc/yum.repos.d/文件夹下</li><li>验证repo文件是否起效<ul><li>yum list|grep cloudera</li><li>如果列出的不是你安装的版本，执行下面命令重试</li><li>yum clean all</li><li>yum list | grep cloudera</li></ul></li><li>将之前下载的rpms文件拷贝到所有节点下（任意目录）<ul><li>切换到rpms目录下，执行</li><li>yum -y install *.rpm</li></ul></li><li>将之前下载的Parcel那3个文件拷贝到/opt/cloudera/parcel-repo目录下（如果没有该目录，请自行创建）<ul><li>至此，/opt/cloudera/parcel-repo下面有三个文件： CDH-5.2.0-1.cdh5.2.0.p0.36-el6.parcel,mainfest.json,CDH-5.2.0-1.cdh5.2.0.p0.36-el6.parcel.sha</li></ul></li><li>主节点启动manager安装：<ul><li>sudo chmod +x ./cloudera-manager-installer.bin</li><li>./cloudera-manager-installer.bin</li></ul></li><li>删除已经存在的db.properties<ul><li>mv /etc/cloudera-scm-server/db.properties /etc/cloudera-scm-server/db.properties.bak</li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;智子 - 韩都衣舍机器学习平台代号😋&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;一、spark流派&quot;&gt;&lt;a href=&quot;#一、spark流派&quot; class=&quot;headerlink&quot; title=&quot;一、spark流派&quot;&gt;&lt;/a&gt;一、spa
      
    
    </summary>
    
      <category term="ML" scheme="/categories/ML/"/>
    
    
  </entry>
  
  <entry>
    <title>《兜兜睡前故事》-- 杰克</title>
    <link href="/2018/02/02/%E5%85%9C%E5%85%9C%E6%BB%91%E6%9D%BF/"/>
    <id>/2018/02/02/兜兜滑板/</id>
    <published>2018-02-02T15:17:42.000Z</published>
    <updated>2018-12-21T09:06:02.310Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>今天兜兜突然说：“爸爸，我想听一个滑板车的故事”。<br>于是就有了这么个故事。</p><p>通过故事打算让她懂得什么？</p><p>勇于尝试、不惧失败、坚持、勤学善问<br>那么故事开始吧 ^_^</p></blockquote><p><img src="https://i.loli.net/2018/12/21/5c1caba0d6f67.jpg" alt="兜兜滑板"></p><p>曾经有一个小男孩，他的名字叫杰克。</p><p>今天是杰克的3岁生日，作为生日礼物呢，他的爸爸送给他了一个滑板车。这个特别的“滑板车”跟兜兜有的这个不太一样。这个滑板车没有可以手抓的扶手，只有一个板子以及板子下面的四个轮子，它还有一个更贴切的名字叫做“滑板”。</p><p>杰克也是第一次见到这个神奇的滑板车，他之前呢，跟兜兜一样，也只会玩带扶手的滑板车。<br>他很好奇，这个滑板该如何玩呢？他一支脚丫小心翼翼的踏了上去，当打算把另一支脚丫也挪上去的时候，滑板往前一滑，杰克摔了一个屁股蹲。</p><p>杰克大声的哭了起来，屁股也在火辣辣的痛，一边哭着一边喊：“这个滑板不好，再也不玩它了。。唔。。”。</p><p>在一旁的爸爸走过来，扶起了杰克，对他说：“杰克，你也摔跤了呀，看来跟我小时候一样呀。你知道吗，杰克，爸爸小时候玩滑板的时候，摔的可惨了”。爸爸摸了摸自己的屁股，若有所思的说：“啊~我想当初估计屁股肯定已经被摔成四半儿了吧”。</p><p>杰克哈哈笑了起来，问爸爸：“真的呀，爸爸你小时候玩这个也摔跤了呀~”</p><p>爸爸认真的说：“是呀，当时摔的好惨呀，不过我后来还是学会玩滑板啦，杰克你想知道爸爸是怎么学滑板的吗？”。杰克说：“嗯嗯嗯，我要听”。</p><p>爸爸点了点头说：“好吧，那我就来讲讲我学滑板的故事吧~”。</p><p>“刚开始，我也跟杰克一样，摔了好多屁股蹲，咳咳，具体多少次我都记不清楚了。。”</p><p>“但是我并没有因为疼就放弃了，因为那时候玩具少，有这么个玩具就很不容易啦。我于是在一次次摔跤、一次次失败中总结经验。一个星期后，我竟然神奇的学会了玩滑板，好吧，只是不会那么频繁摔跤啦。”</p><p>“一个月过去啦，我的滑板技术越来越好啦，甚至可以滑着滑板去学校。然后我竟然教会了我的一些同学们玩滑板，我是不是很厉害呀？😎”</p><p>“杰克，要不要爸爸也教教你呀，爸爸相信你一定能学会玩滑板哒~”</p><p>杰克摸了摸头说：“好吧，我再试试看，爸爸你教教我吧”。</p><p>杰克爸爸于是给杰克仔细讲了讲玩滑板的一些方法窍门。杰克虽然听得很认真，不过还是摔了好几跤。但是杰克想像爸爸那样学会玩滑板，而且爸爸也一直在身边鼓励教导着他，他于是坚持了下来。两天之后，杰克已经可以在滑板上比较稳的前进啦。一个星期后，杰克学会了玩滑板。感受到滑板的乐趣后，他已经完全忘记了之前学习滑板时摔过的屁股蹲了。</p><p>刚开始学做一件事情，起初往往都不会那么顺利，就像学滑板这样，总要摔那么几个屁股蹲。但是如果想要真正学会它，感受学会它后所能收获的快乐，就需要坚持与勇敢尝试了。相信自己的力量，多向身边的人请教，比如有不懂的地方，可以问问爸爸妈妈或者奶奶，有了这些帮助呢，就会让做这件事情，变得稍稍容易一些。</p><p>好了，今天的故事讲完啦，睡吧，晚安，爸爸会陪在你身边，伴你成长。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;今天兜兜突然说：“爸爸，我想听一个滑板车的故事”。&lt;br&gt;于是就有了这么个故事。&lt;/p&gt;
&lt;p&gt;通过故事打算让她懂得什么？&lt;/p&gt;
&lt;p&gt;勇于尝试、不惧失败、坚持、勤学善问&lt;br&gt;那么故事开始吧 ^_^&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;
      
    
    </summary>
    
      <category term="兜兜" scheme="/categories/%E5%85%9C%E5%85%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>《兜兜睡前故事》-- 安妮</title>
    <link href="/2018/01/31/%E5%85%9C%E5%85%9C%E7%9D%A1%E5%89%8D%E6%95%85%E4%BA%8B/"/>
    <id>/2018/01/31/兜兜睡前故事/</id>
    <published>2018-01-31T15:34:51.000Z</published>
    <updated>2018-11-12T09:14:46.988Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>兜兜快三岁了，渐渐进入了第二个叛逆期，该如何告诉她一些事情呢，既然每晚都要讲睡前故事，索性原创一个故事吧。</p><p>通过故事打算让她懂得什么？</p><p>珍惜身边的东西（食物、玩具等）、学会整理自己的东西、发现美好不抱怨、体会独立与坚持、感恩之心。<br>那么故事开始吧 ^_^</p></blockquote><p>很久很久以前，在离城堡不远的地方有一个小村庄。</p><p>村庄里面有一个小女孩，她的名字叫作安妮。安妮多大呢，大约就跟兜兜这么大吧，也是一个漂亮的小姑娘。</p><p>安妮家并不那么富裕，甚至说有一些贫穷。安妮家里有爸爸、妈妈还有奶奶。每天爸爸妈妈都要早出晚归，出去工作，努力赚钱。因为只有赚到钱，才能去买面包、馒头这些吃的东西，才能勉强维持一家人的生计。因为家里吃的东西都来之不易，都是爸爸妈妈辛苦工作换来的，所以安妮从小就养成了珍惜食物的好习惯。每到吃饭的时候，安妮都主动坐到自己的小板凳上，自己吃饭。每次都把自己的那份食物吃的干干净净，从不挑食，因为她知道只有好好吃饭，吃各种食物才能让自己的身体棒棒哒，快快成长~</p><p>安妮只有一个布娃娃，并不像兜兜这样有那么多的玩具。安妮的这个娃娃虽然是奶奶用旧衣服缝制而成的，但却非常的漂亮，安妮也非常喜欢它，娃娃身上总带着奶奶般暖暖的味道。安妮非常的爱护自己的娃娃，就跟爱护她其它的东西一样。每次玩完娃娃，就把它放到一个干净的小盒子中。自己平时画画用的纸笔用完之后，也都好好地整理整齐。因为她知道这些东西都来之不易，要好好珍惜，才能陪伴她更长的时间。</p><p>安妮生日，家里并没有钱去买好吃的奶油蛋糕。安妮并没有吵吵着像其他小朋友那样要吃蛋糕，因为她觉得只要一家人聚在一起陪她过生日就很开心了。爸爸妈妈那天早早的就下班回家。一家四口坐在饭桌前，桌子上点着一支蜡烛，安妮高兴的闭上眼睛许下一个生日愿望，然后睁开眼睛一口气吹灭蜡烛，祈祷自己的愿望能够实现。她把愿望悄悄的告诉我了，兜兜你想知道她许的什么愿望吗？她想快快长大，好好学习，学好多本领，好好工作，用自己的劳动赚好多的钱，让家里的生活变得更好一些。</p><p>安妮渐渐长大了，就像她许的那个愿望那样，好好学习，学到了好多本领。她从小学会了独立与坚持。记得她学跳舞的时候，起初跳得很不好，然而她并没有放弃，而是多加练习，最后出色的完成了一场舞蹈表演。安妮渐渐养成的这些性格习惯，让她出色的完成了很多工作任务。付出的多，回报的也就多。有的时候呢，是金钱上的回报；有的时候呢，可能是能力上的提升，做这些事情以后就更加得心应手啦。</p><p>安妮长大了，爸爸妈妈尤其是奶奶也都渐渐变老了。安妮知道家人们为照顾小时候的她付出了很多，现在她长大了，她要去好好地照顾自己的家人们。她经常回家，跟家人们聊天，彼此倾诉这段日子的生活。像安妮小时候那样，一家人经常在一起吃饭，虽然生活并不那么富裕，但他们都感受到了那最简单的幸福。</p><p>兜兜喜欢安妮吗？是不是有些地方可以向安妮小朋友学习呢？<br>好了，今天的故事讲完啦，睡吧，晚安，爸爸会陪在你身边，伴你成长。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;兜兜快三岁了，渐渐进入了第二个叛逆期，该如何告诉她一些事情呢，既然每晚都要讲睡前故事，索性原创一个故事吧。&lt;/p&gt;
&lt;p&gt;通过故事打算让她懂得什么？&lt;/p&gt;
&lt;p&gt;珍惜身边的东西（食物、玩具等）、学会整理自己的东西、发现美好不抱怨、体会独立与坚持、
      
    
    </summary>
    
      <category term="兜兜" scheme="/categories/%E5%85%9C%E5%85%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>岁月 - 共度余下的时光</title>
    <link href="/2018/01/21/%E5%B2%81%E6%9C%88/"/>
    <id>/2018/01/21/岁月/</id>
    <published>2018-01-20T16:52:34.000Z</published>
    <updated>2018-12-21T09:08:35.769Z</updated>
    
    <content type="html"><![CDATA[<h2 id="传送门"><a href="#传送门" class="headerlink" title="传送门"></a>传送门</h2><p><a href="https://itunes.apple.com/cn/app/%E5%B2%81%E6%9C%88-%E5%85%B1%E5%BA%A6%E4%BD%99%E4%B8%8B%E7%9A%84%E6%97%B6%E5%85%89/id1334705330?mt=8" target="_blank" rel="noopener">App Store下载地址</a><br><img src="https://i.loli.net/2018/12/21/5c1caba0be7e5.png" alt="qrcode"></p><h2 id="先立Flag😇"><a href="#先立Flag😇" class="headerlink" title="先立Flag😇"></a>先立Flag😇</h2><p>无论是否继续从事移动端方向，每年都会抽时间独立设计研发一枚App。并不那么看重实际收入，在乎的是从产品设计、UED到研发与运营的综合磨砺~</p><blockquote><p>番外：这个app已经拖延了有半年之久，这一晃快过年了，赶紧趁周末集中收了收尾。。。<br>App都是全球市场哒，顺便锻炼了下我蹩脚的英文=。=</p></blockquote><h2 id="一、产品向"><a href="#一、产品向" class="headerlink" title="一、产品向"></a>一、产品向</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>某日刷头条，刷到了类似“人生A4纸”的实验视频（具体视频已经找不到了。。）。实验对当时的自己触动很大，可能跟那时自己的生活也有关系吧。于是就决定利用自己的能力做一个App去帮助我们不要留下遗憾。</p><blockquote><p>这里搜到几个相似的视频，列在这里吧。<br><a href="http://v.youku.com/v_show/id_XOTMyNjI5NzMy.html?spm=a2h0k.8191407.0.0&amp;from=s1.8-1-1.2&amp;f=27605031" target="_blank" rel="noopener">人生A4纸解释</a><br><a href="https://v.qq.com/x/page/e01933oenij.html" target="_blank" rel="noopener">人生A4纸社会实验</a></p></blockquote><h3 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h3><p>岁月流逝，流出一缕清泉，流出一阵芳香；齿月年轮，只剩下苍白的脸，无奈的守候；回忆流沙，谁都看不到他的身影，谁都听不到他的脚步，一切都在流逝中进行，在流逝中生长。</p><p>我们尚还年轻，但亲人们却已渐渐老去，对他们来说剩余可支配的岁月已不如我们一般充裕。</p><p>人这一辈子，以百年计量，最后十年，身体行动已不灵便。父母们为我们辛苦了大半辈子，退休之后，实则乐年岁月已无多。珍惜与至亲在一起的每一年，忙碌的生活，也总能拿出几日专心的陪伴他们。不要做让自己的后悔的事情。</p><p>如果有一天，你发现父母老是咳个不停；如果有一天，你发现父母过马路反应慢了；如果有一天，你发现父母不再爱出门；如果有一天，你发现父母脸上多了皱纹；如果有这么一天，说明父母真的老了…… 树欲静而风不止、子欲养而亲不在，你留意过自己的父母吗？</p><h3 id="“岁月”能帮到什么"><a href="#“岁月”能帮到什么" class="headerlink" title="“岁月”能帮到什么"></a>“岁月”能帮到什么</h3><p>“岁月”帮您生成自己与亲人朋友们的岁月卡片，会默认刨去生命最后的十年，真实显露出你们可共度岁月的珍贵。</p><p>“岁月”帮您生成从现在到他们生命尽头每一年的计划卡片，每一年计划为他们做一些事情，珍视在一起的每一年。</p><h2 id="二、UED"><a href="#二、UED" class="headerlink" title="二、UED"></a>二、UED</h2><h3 id="“岁月”模样"><a href="#“岁月”模样" class="headerlink" title="“岁月”模样"></a>“岁月”模样</h3><p><img src="https://i.loli.net/2018/12/21/5c1cabba61943.png" alt="OneLifeGloba"></p><h3 id="设计要素"><a href="#设计要素" class="headerlink" title="设计要素"></a>设计要素</h3><ul><li>卡片式统一风格</li><li>字幕式引导(初始化 + 卡片生成)：<ul><li>增加仪式感与冥想间隙</li><li>沉浸式体感</li></ul></li><li>动效<ul><li>卡片进度重放动画</li><li>剩余岁月数字倒计时</li><li>controller切换动画逻辑划分</li></ul></li><li>配色（一段艰辛的尝试）<ul><li>sip爬取了多个dribbble相关配色方案</li><li>不断尝试调整</li><li>男式配色与女士配色的区分</li></ul></li></ul><h2 id="三、研发"><a href="#三、研发" class="headerlink" title="三、研发"></a>三、研发</h2><blockquote><p>额。。真正用于研发的时间其实并不多。。</p></blockquote><h3 id="用到了什么"><a href="#用到了什么" class="headerlink" title="用到了什么"></a>用到了什么</h3><ul><li>Swift4: 顺道熟悉了一遍语法知识。猫神的书第一时间推送了更新，赞一个哈。</li><li>WCDB: 微信开源的数据库封装，实践整体效果不错。</li><li>RazzleDazzle: 借助该库封装了一个字幕式动画组件。</li><li>Xcode9: 整体好评，有些bug也是醉了。。。（新模拟器截商店展示图好痛苦😂）</li><li>。。。</li></ul><h3 id="学到了什么"><a href="#学到了什么" class="headerlink" title="学到了什么"></a>学到了什么</h3><blockquote><p>以温故知识为主，毕竟目前已经转战ML，并未采用较为突进的架构设计。</p></blockquote><ul><li>iPhoneX相关适配原则。</li><li>Swift4迭代学习。</li><li>Xcode9构建上传应用的流程体验。</li><li>。。。</li></ul><h2 id="四、运营"><a href="#四、运营" class="headerlink" title="四、运营"></a>四、运营</h2><blockquote><p>大大的短板，不过身边有好哥们PD(The One)这块比较擅长，今后可以多多请教。</p></blockquote><p>因为应用为全球市场，除中国大陆外，准备重点尝试下Apple Search Ads的效果。<br>（国内为啥迟迟没有开放。。擦）</p><h2 id="Next"><a href="#Next" class="headerlink" title="Next"></a>Next</h2><ul><li>加入更多的卡片扩展（比如3张生命卡片的链接）。Link more life.</li><li>规划部分的维度细化。</li><li>。。。</li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>“时光匆匆”<br>“是否忘记了某个人”<br>“某位很重要的人”<br>“可能你还年轻”<br>“他们却已悄悄老去”<br>“可共度的岁月已不多”<br>“一起为他们做些什么吧”</p><blockquote><p>2018年1月31日前应用限免，感兴趣的同学多多给予反馈建议哈</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;传送门&quot;&gt;&lt;a href=&quot;#传送门&quot; class=&quot;headerlink&quot; title=&quot;传送门&quot;&gt;&lt;/a&gt;传送门&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://itunes.apple.com/cn/app/%E5%B2%81%E6%9C%88-%E5%85
      
    
    </summary>
    
      <category term="个人作品" scheme="/categories/%E4%B8%AA%E4%BA%BA%E4%BD%9C%E5%93%81/"/>
    
    
  </entry>
  
  <entry>
    <title>iOSer&#39;s 跨界之路</title>
    <link href="/2017/11/10/iOSer&#39;s%E8%B7%A8%E7%95%8C%E4%B9%8B%E8%B7%AF/"/>
    <id>/2017/11/10/iOSer&#39;s跨界之路/</id>
    <published>2017-11-10T07:32:10.000Z</published>
    <updated>2018-12-21T09:05:43.622Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>又到一年双十一，做一下从阿里回家这段日子的思想汇报吧~</p></blockquote><h2 id="Part-One-在阿里这段日子的收获"><a href="#Part-One-在阿里这段日子的收获" class="headerlink" title="Part One 在阿里这段日子的收获"></a>Part One 在阿里这段日子的收获</h2><blockquote><p>呜谢这段日子阿里小伙伴们的帮助与陪伴（人太多，就不一一感谢啦😙）。</p></blockquote><h3 id="一、技能"><a href="#一、技能" class="headerlink" title="一、技能"></a>一、技能</h3><h4 id="Develop"><a href="#Develop" class="headerlink" title="Develop"></a>Develop</h4><blockquote><p>很多东西都是相通的，许多知识都可以互相反哺。<br>回忆几个印象深刻的侧影吧（排名不分先后）。</p></blockquote><ul><li>跟着土土哥反编译源码探究一个诡异问题的内在原因。</li><li>和老谭一起讨论一个问题的最佳实现策略。（代码生成器。。超越手淘的金钟罩）</li><li>毒姐号称要超越YY的缓存库。</li><li>晓明哥惊世骇俗的服务中间层SP。</li><li>平哥的数据驱动型UI组件库。（以及对胸部的了解。。。）</li><li>宪华的只要两行代码~（强调对于代码的封装与精简极致）</li><li>茶哥、远哥对于组件化的规划与推进。</li><li>贤哥RTL的完美方案。</li><li>东伟网络库与混合容器（包含weex）的整合优化。</li><li>仁哥：“多思考总结，做每件事情最后能让你得到些什么”（偶尔看到仁哥代码的喜悦）。😇</li></ul><h4 id="PM"><a href="#PM" class="headerlink" title="PM"></a>PM</h4><blockquote><p>免责声明，粗略一写，纯个人体会😆</p></blockquote><p><img src="https://i.loli.net/2018/12/21/5c1cabc077e8b.png" alt="阿里项目流程"></p><h3 id="二、思想"><a href="#二、思想" class="headerlink" title="二、思想"></a>二、思想</h3><blockquote><p>其实感觉来阿里的这段日子，思想上的转变可能更重要一些。</p></blockquote><h4 id="产品Owner意识"><a href="#产品Owner意识" class="headerlink" title="产品Owner意识"></a>产品Owner意识</h4><blockquote><p>体会颇深。</p></blockquote><p>程序猿们通过对于产品的思考，形成一个可行的初步规划（先跟自己的主管交流一下）。然后去跟产品交流这个规划的可行性，从不同角度达成共识后，技术发起的产品需求便会跟随迭代推进下去。</p><p>程序猿对于产品演进的方向会有自己的思考，结合技术视野，往往能与产品碰撞出不少可行的方案。对于程序猿产出的产品目标是可以写进自己KPI中的，那么也就会以需求Owner的角色负责将方案完善，整合资源，推进产品目标的达成。</p><p>对于业务产品的深度理解、思考与实践，作为一个产品的“Owner”去打磨她，她也会用最好的数据表现来回报Owner们–人人都是产品经理。</p><h4 id="善于总结"><a href="#善于总结" class="headerlink" title="善于总结"></a>善于总结</h4><blockquote><p>说到总结，也是因为之前总结了一篇博文，才被宪华推荐的。</p></blockquote><h4 id="1-知识"><a href="#1-知识" class="headerlink" title="1. 知识"></a>1. 知识</h4><p>小伙伴们都很善于总结，有的画导图，有的写ppt，团队云雀上的分享也干货满满（于是回来后，赶紧自己也用gitbook自建了一个团队的知识库😎）。</p><blockquote><p>带来的好处很多，比如知识结构化、系统化、知识的传承等。</p></blockquote><p>关注每次努力后自己的成长。有些功能可能上线不久就废弃了，不用伤心，因为宝贵的知识、经验与感悟已经留在我们的身上。</p><h4 id="2-数据"><a href="#2-数据" class="headerlink" title="2.数据"></a>2.数据</h4><p>对自己负责模块的数据表现应该做到了如指掌。数据表现背后的意义是什么；如何埋点才能完善数据路径，进而准确推算用户行动链。有了完善的数据行为反馈，对于引导未来的产品方向具有重要意义。</p><blockquote><p>回来的这段日子，自己的职业方向跟数据更亲密了，接下来总结下这段时间搞得一些东东（想到哪写到哪，不苛求逻辑性。。。）。</p></blockquote><h2 id="Part-Two-为什么回来"><a href="#Part-Two-为什么回来" class="headerlink" title="Part Two 为什么回来"></a>Part Two 为什么回来</h2><blockquote><p>感谢文哥、剑哥、亮哥等韩都老朋友的收留。😋</p></blockquote><ul><li><p>横向发展的思考：</p><ul><li>对于移动端大环境的思考。</li><li>横向扩展：<ul><li>对于AI方向的思考尝试。</li><li>大前端跟潮。</li><li>后端知识弥补。</li><li>项目管理尝试。</li><li>。。。</li></ul></li></ul></li><li><p>家庭生活因素的综合考量：</p><ul><li>家人关怀。</li><li>房价。。。</li><li>上学。。。</li><li>。。。</li></ul></li></ul><h2 id="Part-Three-折腾了什么"><a href="#Part-Three-折腾了什么" class="headerlink" title="Part Three 折腾了什么"></a>Part Three 折腾了什么</h2><blockquote><p>一晃回来快3个月了。</p></blockquote><h3 id="一、对自己的几点要求"><a href="#一、对自己的几点要求" class="headerlink" title="一、对自己的几点要求"></a>一、对自己的几点要求</h3><ul><li>既然是跨界，开始往往会比较痛苦，坚持不退缩。</li><li>不为自己设限。</li><li>多总结多沉淀。</li><li>保持产品思维。</li></ul><h3 id="二、技术栈"><a href="#二、技术栈" class="headerlink" title="二、技术栈"></a>二、技术栈</h3><blockquote><p>全是一波新东西，受益匪浅。</p></blockquote><h4 id="1-机器学习"><a href="#1-机器学习" class="headerlink" title="1. 机器学习"></a>1. 机器学习</h4><blockquote><p>感谢文哥的悉心教导😘</p></blockquote><h4 id="搞出来的一些东东"><a href="#搞出来的一些东东" class="headerlink" title="搞出来的一些东东"></a>搞出来的一些东东</h4><ul><li>spark mllib流派：<a href="http://alithink.com/2017/11/09/%E9%94%80%E5%94%AE%E9%A2%84%E6%B5%8B%E6%A1%88%E4%BE%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" target="_blank" rel="noopener">销售预测案例源码分析</a></li><li>sklearn流派：<a href="http://alithink.com/2017/11/09/%E9%94%80%E5%94%AE%E9%A2%84%E6%B5%8B%E7%88%86%E6%97%BA%EF%BC%88scikit-learn%E7%89%88%E6%9C%AC%EF%BC%89/" target="_blank" rel="noopener">销售预测爆旺（scikit-learn版本）</a></li></ul><h4 id="几点体会"><a href="#几点体会" class="headerlink" title="几点体会"></a>几点体会</h4><ul><li>记得路上听得到音频时也讲过，做AI或者ML方向，坚实的理论基础以及对于业务的深刻理解是非常重要的。而这块也是目前我最最最欠缺的（当然其它方面也欠缺😆）。将来要猛补这方面知识。<ul><li>推荐几本入门的好书：<ul><li>spark方向： 《spark机器学习》（PACKT）</li><li>sklearn方向（推荐这个方向，解决方案更丰富一些）：《白话大数据与机器学习》<ul><li>这本书估计高手们都不屑一顾吧，不过感觉很适合我。从最基础的理论开始讲起，对于已经把高数，概率论已经忘干净的人士来说，太有帮助了。。（部分笔记分享一下）</li></ul></li></ul></li></ul></li></ul><p><img src="https://i.loli.net/2018/12/21/5c1cabc0cdd3c.png" alt="白话大数据与机器学习"></p><ul><li>良好的数据基础是必要条件。良好的周期性数据积累，对于各数据变动节点相关数据的完备与丰富，会为ML分析打下坚实的基础。</li><li>数据探索是个体力活。不断对比相关度，探索特征相关性。发现一条规律弥足珍贵。</li><li>传统的专家模式，在维度较少的情况下，还能看的过来；维度数量上来了，机器的优势就上来了。</li><li>各种算法都是浮云，先做LR再说。。（高手绕行）</li><li>结果的可解释性。。。</li></ul><h4 id="2-前后端"><a href="#2-前后端" class="headerlink" title="2. 前后端"></a>2. 前后端</h4><blockquote><p>我其实是vue党。。</p></blockquote><h4 id="智子（Flask-Bootstrap）"><a href="#智子（Flask-Bootstrap）" class="headerlink" title="智子（Flask + Bootstrap）"></a>智子（Flask + Bootstrap）</h4><p><img src="https://i.loli.net/2018/12/21/5c1caba0f169d.jpg" alt="智子效果"></p><blockquote><p>使用Flask的原因: 算法模型使用sklearn搞得，同是python好基友，于是就直接上手了。</p></blockquote><ul><li>Flask真的很轻，搭建起来异常轻松愉快，推荐一本书《Flask Web开发：基于Python的Web应用开发实战》。<ul><li>单文件也能搞定，但工程拆分之后逻辑就更清楚了（虽然麻烦不少）。</li><li>建议用python virtual环境来搞，可以类比为npm package, cocoapods podfile。</li><li>千万不要virtual clear，太恐怖了，程序一下就没有了，真的啥都不剩了。。。</li></ul></li><li>小应用配合WTForms，前后端表单开发效率神器。</li><li>python写出来的代码看起来还是很德味的，对python的好感度大为提升。</li><li>bootstrap程序猿UI神器。（至少看起来不会那么丑了。。）</li></ul><h4 id="有趣的双十一（实时Dashboard-angular-nebular-Elasticsearch）"><a href="#有趣的双十一（实时Dashboard-angular-nebular-Elasticsearch）" class="headerlink" title="有趣的双十一（实时Dashboard angular + nebular + Elasticsearch）"></a>有趣的双十一（实时Dashboard angular + nebular + Elasticsearch）</h4><blockquote><p>vue党为什么用angular: 因为想用nebular的这套主题。。。</p></blockquote><p><img src="https://i.loli.net/2018/12/21/5c1cabbaaa82b.png" alt="interesting"></p><ul><li>直接看Angular官方文档吧，更新速度实在太快了。。<ul><li>官方的英雄实例很赞，适合入门上手。</li><li>typescript用起来还是很爽的。</li><li>整体还是略重，cli很完备，如果没有cli配个工程估计比较痛苦了。</li><li>先查看自身逻辑再怀疑库逻辑。。（一个ngfor绑定的问题，定位半天发现是自己逻辑写错了。。）</li></ul></li><li>es压秒级查询速度：<ul><li>结合Angular的数据绑定，实时更新效果不错。</li><li>es的查询逻辑可以封装一波，利于复用。</li><li>小白查询编写技巧：<ul><li>书籍推荐：《Elasticsearch服务器开发》（PACKT）</li><li>先用Elasticsearch sql生成一个基本的模板（往往是无法直接拿来用的。。），再进行调整修改。</li><li>查询一定要用keyword…</li></ul></li><li>之前试过es的morelikethis 指定匹配字段，相似度神器哈</li></ul></li></ul><h4 id="3-UED"><a href="#3-UED" class="headerlink" title="3. UED"></a>3. UED</h4><blockquote><p>零星接了点这方面的货，还蛮有意思的哈</p></blockquote><h4 id="培训视频"><a href="#培训视频" class="headerlink" title="培训视频"></a>培训视频</h4><p><img src="https://i.loli.net/2018/12/21/5c1cabba6503a.png" alt="培训"></p><h4 id="双十一H5直播间设计"><a href="#双十一H5直播间设计" class="headerlink" title="双十一H5直播间设计"></a>双十一H5直播间设计</h4><p><img src="https://i.loli.net/2018/12/21/5c1caba118340.png" alt="直播间"></p><h4 id="双十一数据海报"><a href="#双十一数据海报" class="headerlink" title="双十一数据海报"></a>双十一数据海报</h4><p><img src="https://i.loli.net/2018/12/21/5c1cabba5d5a8.png" alt="report"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>持续学习，共同成长。</p><p>最后预祝今晚双十一：“大吉大利，晚上吃鸡~”🐥🐥🐥🐥🐥🐥</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;又到一年双十一，做一下从阿里回家这段日子的思想汇报吧~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Part-One-在阿里这段日子的收获&quot;&gt;&lt;a href=&quot;#Part-One-在阿里这段日子的收获&quot; class=&quot;headerlink&quot;
      
    
    </summary>
    
      <category term="回忆录" scheme="/categories/%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
  </entry>
  
  <entry>
    <title>xgboost填坑</title>
    <link href="/2017/11/09/xgboost%E5%A1%AB%E5%9D%91/"/>
    <id>/2017/11/09/xgboost填坑/</id>
    <published>2017-11-09T14:48:27.000Z</published>
    <updated>2017-11-10T01:18:12.435Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装说明"><a href="#安装说明" class="headerlink" title="安装说明"></a>安装说明</h2><h3 id="OSX"><a href="#OSX" class="headerlink" title="OSX"></a>OSX</h3><ul><li><code>git clone --recursive https://github.com/dmlc/xgboost</code></li><li>gcc6 install<ul><li>gcc7支持有问题</li><li>降级版本安装<code>brew install gcc@6 --without-multilib</code></li></ul></li><li>配置与编译</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd xgboost; cp make/minimum.mk ./config.mk; make -j4</span><br><span class="line">    </span><br><span class="line">// config.mk中需要指定gcc版本  gcc-6/g++-6</span><br><span class="line">cd xgboost; cp make/config.mk ./config.mk; make -j4</span><br></pre></td></tr></table></figure><ul><li><p>【可选】清楚之前的编译内容</p><ul><li>make clean</li><li>make distclean</li></ul></li><li><p>终极情况。。。</p><ul><li><p>清理系统版本gcc</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/bin/</span><br><span class="line">rm cc gcc c++ g++</span><br></pre></td></tr></table></figure></li></ul></li></ul><pre><code>* 配置6系列的gcc，注意看一下自己gcc的版本号<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ln -s /usr/local/Cellar/gcc\@6/6.4.0/bin/gcc-6 cc</span><br><span class="line">ln -s /usr/local/Cellar/gcc\@6/6.4.0/bin/gcc-6 gcc</span><br><span class="line">ln -s /usr/local/bin/c++-6 c++</span><br><span class="line">ln -s /usr/local/bin/g++-6 g++</span><br></pre></td></tr></table></figure></code></pre><ul><li>如何安装到anaconda<ul><li><code>sudo /Users/alithink/anaconda/bin/ipython3 setup.py install</code></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;安装说明&quot;&gt;&lt;a href=&quot;#安装说明&quot; class=&quot;headerlink&quot; title=&quot;安装说明&quot;&gt;&lt;/a&gt;安装说明&lt;/h2&gt;&lt;h3 id=&quot;OSX&quot;&gt;&lt;a href=&quot;#OSX&quot; class=&quot;headerlink&quot; title=&quot;OSX&quot;&gt;&lt;/a&gt;OS
      
    
    </summary>
    
      <category term="ML" scheme="/categories/ML/"/>
    
    
  </entry>
  
  <entry>
    <title>销售预测爆旺（scikit-learn版本）</title>
    <link href="/2017/11/09/%E9%94%80%E5%94%AE%E9%A2%84%E6%B5%8B%E7%88%86%E6%97%BA%EF%BC%88scikit-learn%E7%89%88%E6%9C%AC%EF%BC%89/"/>
    <id>/2017/11/09/销售预测爆旺（scikit-learn版本）/</id>
    <published>2017-11-09T14:43:52.000Z</published>
    <updated>2018-12-21T09:12:11.134Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>悼念一下回归模型的悲剧，先尝试一下分类模型，稍后再整他</p></blockquote><h2 id="1-数据探索"><a href="#1-数据探索" class="headerlink" title="1 数据探索"></a>1 数据探索</h2><blockquote><p>sparkSQL支持用sql对数据集进行分析，数据探索工作仍然大部分放在spark中来完成</p></blockquote><h3 id="1-1-🔑发现的一些相关性"><a href="#1-1-🔑发现的一些相关性" class="headerlink" title="1.1 🔑发现的一些相关性"></a>1.1 🔑发现的一些相关性</h3><blockquote><p>对应的数值越接近1表示正相关性越大，越接近-1表示负相关性越大，越接近0表示相关性越小</p></blockquote><ul><li>销售额的相关度往往好于销量<ul><li>毛利率、销量以及库存周转率的权衡在销售额上综合体现了？</li><li>销售任务的导向作用?</li></ul></li><li><p>排除极low款与爆款的前提下</p><ul><li>新货前30天预测后30天相关性较大</li><li><p>新货前30天预测整个商品季相关性较大</p><ul><li>放开爆款，反而销量的相关度上去了</li><li>销售额的相关度有所下降</li></ul><ul><li><img src="https://i.loli.net/2018/12/21/5c1cabba1faf7.jpg" alt="15060597682343"></li><li><img src="https://i.loli.net/2018/12/21/5c1caba091d02.jpg" alt="15060602769621"></li><li><img src="https://i.loli.net/2018/12/21/5c1caba09e791.jpg" alt="15060632132189"></li></ul></li></ul></li><li>冬装数据太奇葩了，基本依托于两个大活动走货<ul><li>考虑要把冬装单独拆分出模型来搞</li><li>其它季节货品使用一个预测模型</li><li>只保留冬季的情况<br><img src="https://i.loli.net/2018/12/21/5c1cabba244a6.jpg" alt="15063072795952"></li></ul></li></ul><h3 id="1-2-决定尝试分offset构建模型"><a href="#1-2-决定尝试分offset构建模型" class="headerlink" title="1.2 决定尝试分offset构建模型"></a>1.2 决定尝试分offset构建模型</h3><h4 id="1-2-1-预测商品级销量分类段划分：offset-total-quantity"><a href="#1-2-1-预测商品级销量分类段划分：offset-total-quantity" class="headerlink" title="1.2.1 预测商品级销量分类段划分：offset_total_quantity"></a>1.2.1 预测商品级销量分类段划分：offset_total_quantity</h4><table><thead><tr><th>Offset（销量）</th><th>正分类（大于offset）</th><th>负分类(小于offset)</th></tr></thead><tbody><tr><td>1000</td><td>1477</td><td>4471</td></tr><tr><td>1600</td><td>1016</td><td>4932</td></tr><tr><td>10000</td><td>204</td><td>5744</td></tr><tr><td>50000</td><td>16</td><td>5932</td></tr></tbody></table><h4 id="1-2-2-参考周期划分："><a href="#1-2-2-参考周期划分：" class="headerlink" title="1.2.2 参考周期划分："></a>1.2.2 参考周期划分：</h4><blockquote><p>重点调优放在前三个档，因为参考周期太长，预测的意义也就小了</p></blockquote><ul><li>前3天：offset3_quantity</li><li>前7天：offset7_quantity</li><li>前15天：offset15_quantity</li><li>前30天：offset30_quantity </li></ul><h2 id="2-开撸"><a href="#2-开撸" class="headerlink" title="2 开撸"></a>2 开撸</h2><blockquote><p>代码的注释基本都用的英文，不是为了装逼，是怕有字符集兼容问题。。。</p></blockquote><h3 id="2-1-包引入"><a href="#2-1-包引入" class="headerlink" title="2.1 包引入"></a>2.1 包引入</h3><blockquote><p>大致分为三类: 数据操作类、sklearn相关、可视化相关。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># package import</span></span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">from</span> string <span class="keyword">import</span> Template</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score,f1_score</span><br><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> plotly.offline <span class="keyword">import</span> download_plotlyjs, init_notebook_mode, plot, iplot</span><br><span class="line"><span class="keyword">import</span> plotly.plotly <span class="keyword">as</span> py</span><br><span class="line"><span class="keyword">import</span> plotly.graph_objs <span class="keyword">as</span> go</span><br></pre></td></tr></table></figure><h4 id="核心包简介"><a href="#核心包简介" class="headerlink" title="核心包简介"></a>核心包简介</h4><ul><li>pandas: 数据集读取操作查询转换输出库。</li><li>sklearn: scikit-learn提供的ML相关方法实现库。<ul><li>preprocessing: 特征预处理相关。</li><li>model_selection: model所需的数据集选取生成。</li><li>metrics: 模型效果评估相关方法。</li><li>externals: 模型持久化相关。</li></ul></li><li>plotly: 发现的一个第三方可视化库，比matplotlib操作起来简单，生成图形可以交互分享，但是间歇性被墙。。😂</li></ul><h2 id="2-辅助函数声明"><a href="#2-辅助函数声明" class="headerlink" title="2. 辅助函数声明"></a>2. 辅助函数声明</h2><h3 id="2-1-生成对应offset的类标"><a href="#2-1-生成对应offset的类标" class="headerlink" title="2.1 生成对应offset的类标"></a>2.1 生成对应offset的类标</h3><blockquote><p>类标生成辅助方法，方法会塞入到pandas dataframe的apply方法中，默认会传入row</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_hot_product_label</span><span class="params">(row, offset, column_index)</span>:</span></span><br><span class="line">    <span class="string">"""Classification label generator.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        row: pandas dataframe row.</span></span><br><span class="line"><span class="string">        offset: Classification offset, such as 1000, 1600, 10000, 50000.</span></span><br><span class="line"><span class="string">        column_index: Dataframe row[column_index], such as row[12].</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        Result of row_column value above offset. For example:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        1: row_column &gt;= offset.</span></span><br><span class="line"><span class="string">        0: row_column &lt; offset.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> (row[column_index] &gt;= offset):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><h3 id="2-2-特征变换"><a href="#2-2-特征变换" class="headerlink" title="2.2 特征变换"></a>2.2 特征变换</h3><blockquote><p>减少特征之间或者特征与类标之间取值差距，blablabla</p></blockquote><h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><blockquote><p>log辅助方法</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log_quantity</span><span class="params">(row, column_index)</span>:</span></span><br><span class="line">    <span class="string">"""Log the value."""</span></span><br><span class="line">    <span class="keyword">return</span> log(row[column_index])</span><br></pre></td></tr></table></figure><blockquote><p>标准化转换</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">standardScalerTransform</span><span class="params">(X_train, X_test)</span>:</span></span><br><span class="line">    <span class="string">"""StandardScaler transform."""</span></span><br><span class="line">    sc = StandardScaler()</span><br><span class="line">    sc.fit(X_train)</span><br><span class="line">    <span class="keyword">return</span> (sc.transform(X_train), sc.transform(X_test))</span><br></pre></td></tr></table></figure><blockquote><p>min-Max转换</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minMaxTransform</span><span class="params">(X_train, X_test)</span>:</span></span><br><span class="line">    <span class="string">"""MinMaxScaler transform."""</span></span><br><span class="line">    sc = MinMaxScaler()</span><br><span class="line">    sc.fit(X_train)</span><br><span class="line">    <span class="keyword">return</span> (sc.transform(X_train), sc.transform(X_test))</span><br></pre></td></tr></table></figure><h3 id="2-3-样本均匀化"><a href="#2-3-样本均匀化" class="headerlink" title="2.3 样本均匀化"></a>2.3 样本均匀化</h3><h4 id="前情回顾"><a href="#前情回顾" class="headerlink" title="前情回顾"></a>前情回顾</h4><blockquote><p>正负样本分布不均匀，需要均匀化处理，使得正负样本数基本一致。<br>隆重介绍<strong>imblearn</strong>库，提供各种样本均匀化算法的实现。</p></blockquote><table><thead><tr><th>Offset（销量）</th><th>正分类（大于offset）</th><th>负分类(小于offset)</th></tr></thead><tbody><tr><td>1000</td><td>1477</td><td>4471</td></tr><tr><td>1600</td><td>1016</td><td>4932</td></tr><tr><td>10000</td><td>204</td><td>5744</td></tr><tr><td>50000</td><td>16</td><td>5932</td></tr></tbody></table><h4 id="under-sampling"><a href="#under-sampling" class="headerlink" title="under-sampling"></a>under-sampling</h4><blockquote><p>把多的砍掉，正样本多就砍正样本，负样本多就砍负样本的，最后就一致了。<br>至于如何砍就有很多算法了，这里选用了NearMiss算法。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> imblearn.under_sampling <span class="keyword">import</span> NearMiss</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">under_samplingTransform</span><span class="params">(X, y)</span>:</span></span><br><span class="line">    <span class="string">"""Under-sampling NearMiss mode."""</span></span><br><span class="line">    <span class="keyword">return</span> NearMiss(random_state=<span class="number">0</span>, version=<span class="number">1</span>).fit_sample(X, y)</span><br></pre></td></tr></table></figure><h4 id="over-sampling"><a href="#over-sampling" class="headerlink" title="over-sampling"></a>over-sampling</h4><blockquote><p>哪种样本少了，就想办法造一些，最后就一致了。<br>至于如何造就有很多算法了，这里选用了SMOTE的SVM模式算法。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE, ADASYN</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">over_samplingTransform</span><span class="params">(X, y)</span>:</span></span><br><span class="line">    <span class="string">"""Over-sampling SMOTE svm mode."""</span></span><br><span class="line">    <span class="keyword">return</span> SMOTE(kind=<span class="string">'svm'</span>).fit_sample(X, y)</span><br></pre></td></tr></table></figure><h3 id="2-4-模型算法"><a href="#2-4-模型算法" class="headerlink" title="2.4 模型算法"></a>2.4 模型算法</h3><blockquote><p>最简单的是感知器算法，因为不能解决线性不可分问题，就忽略掉了。。</p></blockquote><h4 id="逻辑斯蒂回归"><a href="#逻辑斯蒂回归" class="headerlink" title="逻辑斯蒂回归"></a>逻辑斯蒂回归</h4><blockquote><p>唬人的名字，说是回归，其实是分类算法。。<br>分类界用的很多。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logisticRegModelGenerator</span><span class="params">(train_std, y_train)</span>:</span></span><br><span class="line">    <span class="string">"""LogisticRegression model generator."""</span></span><br><span class="line">    <span class="keyword">return</span> LogisticRegression(C=<span class="number">1000</span>, random_state=<span class="number">0</span>).fit(train_std, y_train)</span><br></pre></td></tr></table></figure><h4 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h4><blockquote><p>理论上说可以忽略样本分布不均匀的问题（因为属于决策树类的算法）。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_forest_classifier</span><span class="params">(train_x, train_y)</span>:</span>    </span><br><span class="line">    <span class="string">"""Random Forest model generator."""</span> </span><br><span class="line">    <span class="keyword">return</span> RandomForestClassifier(n_estimators=<span class="number">8</span>).fit(train_x, train_y)</span><br></pre></td></tr></table></figure><h4 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h4><blockquote><p>忽然概念名词超多的算法，什么超平面啥的。。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">svm_classifier</span><span class="params">(train_x, train_y)</span>:</span>    </span><br><span class="line">    <span class="string">"""SVM model generator."""</span></span><br><span class="line">    <span class="keyword">return</span> SVC(kernel=<span class="string">'rbf'</span>, probability=<span class="keyword">True</span>).fit(train_x, train_y)</span><br></pre></td></tr></table></figure><h4 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h4><blockquote><p>梯度提升算法（实测在这个场景综合效果较好😘）</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_boosting_classifier</span><span class="params">(train_x, train_y)</span>:</span>    </span><br><span class="line">    <span class="string">"""GBDT model generator."""</span></span><br><span class="line">    <span class="keyword">return</span> GradientBoostingClassifier(n_estimators=<span class="number">200</span>).fit(train_x, train_y)</span><br></pre></td></tr></table></figure><h4 id="xgboost"><a href="#xgboost" class="headerlink" title="xgboost"></a>xgboost</h4><blockquote><p>在kaggle大赛中叱咤风云的神级算法，在这个场景实测效果不如GBDT<br>但xg有些好处，比如可以输出每轮学习时的精确度，以及输出目前输入特征的重要性分数，便于优化调参。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> plot_importance</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xgboost_classifier</span><span class="params">(train_x, train_y)</span>:</span></span><br><span class="line">    <span class="string">"""xgboost model generator."""</span></span><br><span class="line">    model = XGBClassifier()</span><br><span class="line">    model.fit(train_x, train_y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Feature importance.</span></span><br><span class="line">    <span class="comment"># plot_importance(model)</span></span><br><span class="line">    <span class="comment"># pyplot.show()</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><h3 id="2-5-预测类"><a href="#2-5-预测类" class="headerlink" title="2.5 预测类"></a>2.5 预测类</h3><blockquote><p>SalesProphet（销售预言家）：预测辅助类<br>因为各种特征offset、类标、算法的组合，不封装一个类的话，将来会死的。。（已经死过一轮了，改一个东东要累死。。）<br>具体方法作用详见注释哈，总之就是传入参数，调用predit完事。<br>（吐槽python 断言竟然只能在继承于testcase的类中使用。。）</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SalesProphet</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""Sales prediction class.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        datasource: Sales prediction datasource relied on.</span></span><br><span class="line"><span class="string">        features_name: Feature names array.</span></span><br><span class="line"><span class="string">        label_name: Label names String.</span></span><br><span class="line"><span class="string">        model_type: Algorithm of model training.</span></span><br><span class="line"><span class="string">        X: Feature data.</span></span><br><span class="line"><span class="string">        y: Label data.</span></span><br><span class="line"><span class="string">        X_train: X train data.</span></span><br><span class="line"><span class="string">        X_test: X test data.</span></span><br><span class="line"><span class="string">        y_train: y train data.</span></span><br><span class="line"><span class="string">        y_test: y test data.</span></span><br><span class="line"><span class="string">        y_pred: y data predicted.</span></span><br><span class="line"><span class="string">        model: ML model fitted.</span></span><br><span class="line"><span class="string">        accuracy_score: Model accuracy score.</span></span><br><span class="line"><span class="string">        f1_score: Model f1 score.</span></span><br><span class="line"><span class="string">        train_score: Model score in train set.</span></span><br><span class="line"><span class="string">        test_score: Model score in test set.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, datasource, features_name, label_name, model_type=<span class="string">'logistic'</span>)</span>:</span></span><br><span class="line">        <span class="string">"""Inits SalesProphet with datasource, features_name, label_name, model_type(default is logistic)"""</span></span><br><span class="line">        self.datasource = datasource</span><br><span class="line">        self.features_name = features_name</span><br><span class="line">        self.label_name = label_name</span><br><span class="line">        self.model_type = model_type</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feature_engineering</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Feature engineering about: X y generated, one-hot, sampling blabla..."""</span></span><br><span class="line">        <span class="comment"># assertIsNotNone(self.datasource, 'Guys, forget the datasource!!!')</span></span><br><span class="line">        <span class="comment"># assertNotEqual(len(self.features_name), 0, 'features is empty. WTF...')</span></span><br><span class="line">        <span class="comment"># assertNotEqual(len(self.label_name), 0, 'label is empty. WTF...')</span></span><br><span class="line">        </span><br><span class="line">        self.X = self.datasource[self.features_name].values</span><br><span class="line">        self.y = self.datasource[self.label_name]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># one-hot</span></span><br><span class="line">        ohe = OneHotEncoder(categorical_features = [<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">        self.X = ohe.fit_transform(self.X).toarray()</span><br><span class="line">        </span><br><span class="line">        self.X, self.y = over_samplingTransform(self.X, self.y)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_test_transform</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Trainset and testset splitor and standard transform."""</span></span><br><span class="line">        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)</span><br><span class="line">        self.X_train, self.X_test = standardScalerTransform(self.X_train, self.X_test)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">model_fitting</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Algorithm of model selector."""</span></span><br><span class="line">        model_alg_switcher = &#123;</span><br><span class="line">            <span class="string">'logistic'</span>: logisticRegModelGenerator,</span><br><span class="line">            <span class="string">'rf'</span>: random_forest_classifier,</span><br><span class="line">            <span class="string">'svm'</span>: svm_classifier,</span><br><span class="line">            <span class="string">'gdbt'</span>: gradient_boosting_classifier,</span><br><span class="line">            <span class="string">'xgboost'</span>: xgboost_classifier</span><br><span class="line">        &#125;</span><br><span class="line">        func = model_alg_switcher.get(self.model_type, logisticRegModelGenerator)</span><br><span class="line">        <span class="keyword">return</span> func(self.X_train, self.y_train)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">genPredictReport</span><span class="params">(self, printlog=False)</span>:</span></span><br><span class="line">        <span class="string">"""Model estimate report generation. Set printlog YES to pring log."""</span></span><br><span class="line">        self.accuracy_score = accuracy_score(self.y_test, self.y_pred)</span><br><span class="line">        self.f1_score = f1_score(self.y_test, self.y_pred, average=<span class="string">'binary'</span>)</span><br><span class="line">        self.train_score = self.model.score(self.X_train, self.y_train)</span><br><span class="line">        self.test_score = self.model.score(self.X_test, self.y_test)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> printlog:</span><br><span class="line">            print(<span class="string">'/--------------START-------------'</span>)</span><br><span class="line">            print(<span class="string">'|'</span>)</span><br><span class="line">            print(<span class="string">'| feature: %s'</span> % self.features_name)</span><br><span class="line">            print(<span class="string">'| label: %s'</span> % self.label_name)</span><br><span class="line">            print(<span class="string">'| model alg: %s'</span> % self.model_type)</span><br><span class="line">            print(<span class="string">'|'</span>)</span><br><span class="line">            print(<span class="string">'|----Estimate score------'</span>)</span><br><span class="line">            print(<span class="string">'|'</span>)</span><br><span class="line">            print(<span class="string">'| accuracy is: %.2f'</span> % self.accuracy_score)</span><br><span class="line">            print(<span class="string">'| f1_score is: %.2f'</span> % self.f1_score)</span><br><span class="line">            print(<span class="string">'|'</span>)</span><br><span class="line">            print(<span class="string">'|---Over-fitting check---'</span>)</span><br><span class="line">            print(<span class="string">'|'</span>)</span><br><span class="line">            print(<span class="string">'| train-set score: %.2f'</span> % self.train_score)</span><br><span class="line">            print(<span class="string">'| test-set score: %.2f'</span> % self.test_score)</span><br><span class="line">            print(<span class="string">'|'</span>)</span><br><span class="line">            print(<span class="string">'|---------------END--------------/\n'</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">public_genReportChart</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""y_test and y_pred chart generation."""</span></span><br><span class="line">        t = np.arange(len(self.y_pred))</span><br><span class="line">        <span class="comment"># Create traces</span></span><br><span class="line">        trace0 = go.Scatter(</span><br><span class="line">            x = t,</span><br><span class="line">            y = self.y_pred,</span><br><span class="line">            mode = <span class="string">'lines'</span>,</span><br><span class="line">            name = <span class="string">'predict'</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        trace1 = go.Scatter(</span><br><span class="line">            x = t,</span><br><span class="line">            y = self.y_test,</span><br><span class="line">            mode = <span class="string">'lines'</span>,</span><br><span class="line">            name = <span class="string">'real'</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        data = [trace0, trace1]</span><br><span class="line"></span><br><span class="line">        py.iplot(data, filename=<span class="string">'(%self.features_name)_(%self.labels_name)_(%self.model_type.model)'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">public_saveModel</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Model persistence."""</span></span><br><span class="line">        joblib.dump(self.model, <span class="string">'%(self.features_name)_%(self.labels_name)_(%self.model_type.model)'</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Predict main method."""</span></span><br><span class="line">        self.feature_engineering()</span><br><span class="line">        self.train_test_transform()</span><br><span class="line">        </span><br><span class="line">        self.model = self.model_fitting()</span><br><span class="line">        self.y_pred = self.model.predict(self.X_test)</span><br><span class="line">        self.genPredictReport()</span><br></pre></td></tr></table></figure><h2 id="3-数据准备"><a href="#3-数据准备" class="headerlink" title="3. 数据准备"></a>3. 数据准备</h2><h3 id="3-1-数据读取"><a href="#3-1-数据读取" class="headerlink" title="3.1 数据读取"></a>3.1 数据读取</h3><blockquote><p>从spark 导出准备好的数据到csv文件，pandas读取该csv中的数据。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data = pd.read_csv(<span class="string">"data/product_2016_offset_group.csv"</span>)</span><br></pre></td></tr></table></figure><blockquote><p>获取前5条数据看看情况</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data.head()</span><br></pre></td></tr></table></figure><blockquote><p>describe 可以对df中各列的综合指标进行集中展示。<br>比如中位数、均值等等，方便进一步分析数据。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data.describe()</span><br></pre></td></tr></table></figure><h3 id="3-2-销量特征log变换"><a href="#3-2-销量特征log变换" class="headerlink" title="3.2 销量特征log变换"></a>3.2 销量特征log变换</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_data[<span class="string">'log_3_quantity'</span>] = train_data.apply(log_quantity, column_index=<span class="number">8</span>, axis=<span class="number">1</span>)</span><br><span class="line">train_data[<span class="string">'log_7_quantity'</span>] = train_data.apply(log_quantity, column_index=<span class="number">9</span>, axis=<span class="number">1</span>)</span><br><span class="line">train_data[<span class="string">'log_15_quantity'</span>] = train_data.apply(log_quantity, column_index=<span class="number">10</span>, axis=<span class="number">1</span>)</span><br><span class="line">train_data[<span class="string">'log_30_quantity'</span>] = train_data.apply(log_quantity, column_index=<span class="number">11</span>, axis=<span class="number">1</span>)</span><br><span class="line">train_data[<span class="string">'log_total_quantity'</span>] = train_data.apply(log_quantity, column_index=<span class="number">12</span>, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data.head()</span><br></pre></td></tr></table></figure><h3 id="3-3-类标生成"><a href="#3-3-类标生成" class="headerlink" title="3.3 类标生成"></a>3.3 类标生成</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_data[<span class="string">'hot_1000_product'</span>] = train_data.apply(gen_hot_product_label, args=(<span class="number">1000</span>, <span class="number">12</span>), axis=<span class="number">1</span>)</span><br><span class="line">train_data[<span class="string">'hot_1600_product'</span>] = train_data.apply(gen_hot_product_label, args=(<span class="number">1600</span>, <span class="number">12</span>), axis=<span class="number">1</span>)</span><br><span class="line">train_data[<span class="string">'hot_10000_product'</span>] = train_data.apply(gen_hot_product_label, args=(<span class="number">10000</span>, <span class="number">12</span>), axis=<span class="number">1</span>)</span><br><span class="line">train_data[<span class="string">'hot_50000_product'</span>] = train_data.apply(gen_hot_product_label, args=(<span class="number">50000</span>, <span class="number">12</span>), axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_data.head()</span><br><span class="line">train_data[train_data.hot_1000_product == <span class="number">1</span>].count()</span><br></pre></td></tr></table></figure><pre><code>product_code                  1477category_id                   1477season                        1477offset3_amount_actual         1477offset7_amount_actual         1477offset15_amount_actual        1477offset30_amount_actual        1477offset_total_amount_actual    1477offset3_quantity              1477offset7_quantity              1477offset15_quantity             1477offset30_quantity             1477offset_total_quantity         1477log_3_quantity                1477log_7_quantity                1477log_15_quantity               1477log_30_quantity               1477log_total_quantity            1477hot_1000_product              1477hot_1600_product              1477hot_10000_product             1477hot_50000_product             1477dtype: int64</code></pre><h3 id="3-4-数据清洗"><a href="#3-4-数据清洗" class="headerlink" title="3.4 数据清洗"></a>3.4 数据清洗</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data_normal = train_data[train_data.offset30_quantity &lt;= train_data.offset_total_quantity]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data_normal[train_data_normal.offset_total_quantity &lt; <span class="number">0</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># drop null row</span></span><br><span class="line">print(train_data_normal.isnull().sum())</span><br><span class="line">train_data_valid = train_data_normal.dropna()</span><br></pre></td></tr></table></figure><pre><code>product_code                  0category_id                   0season                        0offset3_amount_actual         0offset7_amount_actual         0offset15_amount_actual        0offset30_amount_actual        0offset_total_amount_actual    0offset3_quantity              0offset7_quantity              0offset15_quantity             0offset30_quantity             0offset_total_quantity         0log_3_quantity                0log_7_quantity                0log_15_quantity               0log_30_quantity               0log_total_quantity            0hot_1000_product              0hot_1600_product              0hot_10000_product             0hot_50000_product             0dtype: int64</code></pre><blockquote><ol><li>无序特征做onehot消除次序关系。</li><li>整理特征与类标。</li><li>循环生成预言家，让它预测，生成报告，然后把他丢到预言家数组里面（salesProphets）便于后面生成分析对比用的DataFrame。</li></ol></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># category_id, season onehot</span></span><br><span class="line">feature_disordered = [<span class="string">'category_id'</span>, <span class="string">'season'</span>]</span><br><span class="line"></span><br><span class="line">feature_cols_3 = feature_disordered + [<span class="string">'offset3_quantity'</span>]</span><br><span class="line">feature_cols_7 = feature_disordered + [<span class="string">'offset7_quantity'</span>]</span><br><span class="line">feature_cols_15 = feature_disordered + [<span class="string">'offset15_quantity'</span>]</span><br><span class="line">feature_cols_30 = feature_disordered + [<span class="string">'offset30_quantity'</span>]</span><br><span class="line">feature_offsets = [feature_cols_3, feature_cols_7, feature_cols_15, feature_cols_30]</span><br><span class="line"></span><br><span class="line">label_names = [<span class="string">'hot_1000_product'</span>, <span class="string">'hot_1600_product'</span>, <span class="string">'hot_10000_product'</span>, <span class="string">'hot_50000_product'</span>]</span><br><span class="line"></span><br><span class="line">algs = [<span class="string">'logistic'</span>, <span class="string">'rf'</span>, <span class="string">'svm'</span>, <span class="string">'gdbt'</span>,<span class="string">'xgboost'</span>]</span><br><span class="line"></span><br><span class="line">salesProphets = []</span><br><span class="line"><span class="keyword">for</span> alg <span class="keyword">in</span> algs:</span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> feature_offsets:</span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> label_names:</span><br><span class="line">            salesProphet = SalesProphet(train_data_valid, feature, y, alg)</span><br><span class="line">            salesProphet.predict()</span><br><span class="line">            salesProphet.genPredictReport()</span><br><span class="line">            salesProphets.append(salesProphet)</span><br></pre></td></tr></table></figure><blockquote><p>预言家数组生成综合对比DataFrame</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 整理生成报告DataFrame</span></span><br><span class="line">feature_column = []</span><br><span class="line">label_column = []</span><br><span class="line">model_alg_column = []</span><br><span class="line">accuracy_column = []</span><br><span class="line">f1_score_column = []</span><br><span class="line">trainset_score_column = []</span><br><span class="line">testset_score_column = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> salesProphet <span class="keyword">in</span> salesProphets:</span><br><span class="line">    feature_column.append(salesProphet.features_name)</span><br><span class="line">    label_column.append(salesProphet.label_name)</span><br><span class="line">    model_alg_column.append(salesProphet.model_type)</span><br><span class="line">    accuracy_column.append(salesProphet.accuracy_score)</span><br><span class="line">    f1_score_column.append(salesProphet.f1_score)</span><br><span class="line">    trainset_score_column.append(salesProphet.train_score)</span><br><span class="line">    testset_score_column.append(salesProphet.test_score)</span><br><span class="line"></span><br><span class="line">result_data = &#123;<span class="string">'feature'</span>: feature_column, <span class="string">'label'</span>: label_column, </span><br><span class="line">               <span class="string">'model_alg'</span>: model_alg_column, <span class="string">'accuracy'</span>: accuracy_column, </span><br><span class="line">               <span class="string">'f1_score'</span>: f1_score_column, <span class="string">'trainset_score'</span>: trainset_score_column, </span><br><span class="line">               <span class="string">'testset_score'</span>: testset_score_column&#125;</span><br><span class="line"></span><br><span class="line">result_df = DataFrame(result_data)</span><br></pre></td></tr></table></figure><blockquote><p>分析报告保存</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result_df.to_csv(<span class="string">'data/result_df.csv'</span>)</span><br></pre></td></tr></table></figure><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><h3 id="特征重要性分析"><a href="#特征重要性分析" class="headerlink" title="特征重要性分析"></a>特征重要性分析</h3><blockquote><p>分数越高越重要</p></blockquote><p><img src="https://i.loli.net/2018/12/21/5c1cabba9e6d8.jpg" alt="模型特征重要性分析"></p><h3 id="综合对比"><a href="#综合对比" class="headerlink" title="综合对比"></a>综合对比</h3><blockquote><p>分数越接近1越好</p></blockquote><p><img src="https://i.loli.net/2018/12/21/5c1cabbaa02df.png" alt="综合对比报告"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="http://scikit-learn.org/stable/" target="_blank" rel="noopener">scikit-learn官网</a></li><li><a href="http://contrib.scikit-learn.org/imbalanced-learn/stable/" target="_blank" rel="noopener">imbalanced-learn官网</a></li><li><a href="http://blog.csdn.net/Bryan__/article/details/51288953" target="_blank" rel="noopener">python sklearn分类算法简单调用</a></li><li><a href="http://www.jianshu.com/p/7e0e2d66b3d4" target="_blank" rel="noopener">Kaggle神器xgboost</a></li><li><a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/" target="_blank" rel="noopener">莫烦PYTHON 机器学习专题(需翻墙)</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;悼念一下回归模型的悲剧，先尝试一下分类模型，稍后再整他&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;1-数据探索&quot;&gt;&lt;a href=&quot;#1-数据探索&quot; class=&quot;headerlink&quot; title=&quot;1 数据探索&quot;&gt;&lt;/a&gt;1 数据探索
      
    
    </summary>
    
      <category term="ML" scheme="/categories/ML/"/>
    
    
  </entry>
  
  <entry>
    <title>销售预测案例源码分析</title>
    <link href="/2017/11/09/%E9%94%80%E5%94%AE%E9%A2%84%E6%B5%8B%E6%A1%88%E4%BE%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    <id>/2017/11/09/销售预测案例源码分析/</id>
    <published>2017-11-09T14:35:29.000Z</published>
    <updated>2018-12-21T09:10:20.749Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文重在借案例学习spark相关数据结构与语法</p></blockquote><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><h3 id="1-特征转换"><a href="#1-特征转换" class="headerlink" title="1. 特征转换"></a>1. 特征转换</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> stateHolidayIndexer = <span class="keyword">new</span> <span class="type">StringIndexer</span>()</span><br><span class="line">    .setInputCol(<span class="string">"StateHoliday"</span>)</span><br><span class="line">    .setOutputCol(<span class="string">"StateHolidayIndex"</span>)</span><br><span class="line">  <span class="keyword">val</span> schoolHolidayIndexer = <span class="keyword">new</span> <span class="type">StringIndexer</span>()</span><br><span class="line">    .setInputCol(<span class="string">"SchoolHoliday"</span>)</span><br><span class="line">    .setOutputCol(<span class="string">"SchoolHolidayIndex"</span>)</span><br><span class="line">  <span class="keyword">val</span> stateHolidayEncoder = <span class="keyword">new</span> <span class="type">OneHotEncoder</span>()</span><br><span class="line">    .setInputCol(<span class="string">"StateHolidayIndex"</span>)</span><br><span class="line">    .setOutputCol(<span class="string">"StateHolidayVec"</span>)</span><br><span class="line">  <span class="keyword">val</span> schoolHolidayEncoder = <span class="keyword">new</span> <span class="type">OneHotEncoder</span>()</span><br><span class="line">    .setInputCol(<span class="string">"SchoolHolidayIndex"</span>)</span><br><span class="line">    .setOutputCol(<span class="string">"SchoolHolidayVec"</span>)</span><br><span class="line">  <span class="keyword">val</span> dayOfMonthEncoder = <span class="keyword">new</span> <span class="type">OneHotEncoder</span>()</span><br><span class="line">    .setInputCol(<span class="string">"DayOfMonth"</span>)</span><br><span class="line">    .setOutputCol(<span class="string">"DayOfMonthVec"</span>)</span><br><span class="line">  <span class="keyword">val</span> dayOfWeekEncoder = <span class="keyword">new</span> <span class="type">OneHotEncoder</span>()</span><br><span class="line">    .setInputCol(<span class="string">"DayOfWeek"</span>)</span><br><span class="line">    .setOutputCol(<span class="string">"DayOfWeekVec"</span>)</span><br><span class="line">  <span class="keyword">val</span> storeEncoder = <span class="keyword">new</span> <span class="type">OneHotEncoder</span>()</span><br><span class="line">    .setInputCol(<span class="string">"Store"</span>)</span><br><span class="line">    .setOutputCol(<span class="string">"StoreVec"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> assembler = <span class="keyword">new</span> <span class="type">VectorAssembler</span>()</span><br><span class="line">    .setInputCols(<span class="type">Array</span>(<span class="string">"StoreVec"</span>, <span class="string">"DayOfWeekVec"</span>, <span class="string">"Open"</span>,</span><br><span class="line">      <span class="string">"DayOfMonthVec"</span>, <span class="string">"StateHolidayVec"</span>, <span class="string">"SchoolHolidayVec"</span>))</span><br><span class="line">    .setOutputCol(<span class="string">"features"</span>)</span><br></pre></td></tr></table></figure><ul><li><p>先转化为StringIndexer</p><ul><li>inputCol原始列</li><li><p>outputCol转化为对应的index列: </p><ul><li>从0开始编号，出现频次最多的项目，编号小</li><li>有时候会有着这样的场景</li><li><p>用一个df转换另一个df,当df2对应列中的值超出了df1中的范围时，可以选择策略</p><ul><li>skip：忽略掉</li><li>keep：超出项对应分配一个index</li><li><p>默认为抛出异常</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val indexed2 = indexer.fit(df1).setHandleInvalid(&quot;skip&quot;).transform(df2)</span><br></pre></td></tr></table></figure></li></ul></li></ul></li></ul></li><li><p>做OneHotEncoder</p><ul><li>转化为对应向量</li><li>只指定一位为1，其余为0，出现频率最低的为(最终序号, [], [])</li></ul></li><li>VectorAssembler<ul><li>将对应元素合并成一个向量，打平</li></ul></li></ul><h3 id="2-环境初始化（面向像我这样的小白选手）"><a href="#2-环境初始化（面向像我这样的小白选手）" class="headerlink" title="2. 环境初始化（面向像我这样的小白选手）"></a>2. 环境初始化（面向像我这样的小白选手）</h3><blockquote><p>main中 大部分抄袭文档</p></blockquote><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"alithink"</span>).setMaster(<span class="string">"local"</span>)</span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"><span class="keyword">val</span> sparkSession = <span class="type">SparkSession</span>.builder().getOrCreate()</span><br></pre></td></tr></table></figure><ul><li>SparkConf:<ul><li>Spark各种key-value的配置项<ul><li>setAppName: 给你的应用配置一个名字</li><li>setMaster: 连接到的主URL，例如这里的local代表本地单线程运行，local[4]本地4核运行，或者spark://master:7077 spark典型的Mater/slave模式</li></ul></li></ul></li><li>SparkContext:<ul><li>理解为与spark集群的对接人，可以用她来创建RDDs, accumulators 和 broadcast variables</li><li>每个JVM环境活着的SparkContext只有一个，创建一个新的前先stop（将来这个限制可能会被移除）</li></ul></li><li><p>SparkSession:</p><ul><li>合并了SparkContext和SQLContext<ul><li>内部有对应属性在需要时可以取得对应实例</li></ul></li><li>用于操作DataSet和DataFrame API</li><li><p>使用：</p><ul><li>REPL已经预先创建了（比如spark-shell, zeppelin）</li><li><p>获取已经存在的或者新创建一个：</p><ul><li><code>SparkSession.builder().getOrCreate()</code><ul><li>前提是sparkContext已经创建</li></ul></li><li><p>尽量用SparkSession来接管一切吧（上述代码可以改为如下）</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"alithink"</span>).setMaster(<span class="string">"local"</span>)</span><br><span class="line"><span class="comment">// val sc = new SparkContext(conf)</span></span><br><span class="line"><span class="comment">// val sparkSession = SparkSession.builder().getOrCreate()</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> sparkSession = <span class="type">SparkSession</span>.builder</span><br><span class="line">                 <span class="comment">//.master("local")</span></span><br><span class="line">                 <span class="comment">//.appName("alithink")</span></span><br><span class="line">                 .config(conf)</span><br><span class="line">                 .getOrCreate()</span><br></pre></td></tr></table></figure></li></ul></li></ul></li></ul></li></ul><h3 id="3-训练数据整理"><a href="#3-训练数据整理" class="headerlink" title="3. 训练数据整理"></a>3. 训练数据整理</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main中调用</span></span><br><span class="line"><span class="keyword">val</span> data = loadTrainingData(sparkSession, <span class="string">"/Users/alithink/Space/common_data/train.csv"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 具体实现函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadTrainingData</span></span>(sqlContext:<span class="type">SparkSession</span>, filePath:<span class="type">String</span>):<span class="type">DataFrame</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> trainRaw = sqlContext</span><br><span class="line">    .read.format(<span class="string">"com.databricks.spark.csv"</span>)</span><br><span class="line">    .option(<span class="string">"header"</span>, <span class="string">"true"</span>)</span><br><span class="line">    .load(filePath)</span><br><span class="line">    .repartition(<span class="number">30</span>)</span><br><span class="line">  trainRaw.createOrReplaceTempView(<span class="string">"raw_training_data"</span>)</span><br><span class="line">   </span><br><span class="line">  sqlContext.sql(<span class="string">""</span><span class="string">"SELECT</span></span><br><span class="line"><span class="string">    double(Sales) label, double(Store) Store, int(Open) Open, double(DayOfWeek)   DayOfWeek,</span></span><br><span class="line"><span class="string">    StateHoliday, SchoolHoliday, (double(regexp_extract(Date, '\\d+-\\d+-(\\d+)', 1))) DayOfMonth</span></span><br><span class="line"><span class="string">    FROM raw_training_data</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span>).na.drop()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>SparkSession：<ul><li>read 返回一个DataFrameReader<ul><li>format(读取格式):com.databricks.spark.csv期初为一个开源库，后来已经集成到spark2.*啦</li><li><code>option(&quot;header&quot;, &quot;true&quot;)</code> 使用第一行作为头</li><li>赠送 <code>.option(&quot;inferSchema&quot;, &quot;true&quot;)</code> 自动推导类型</li></ul></li></ul></li><li>DataFrame（粗略一说，内容太多^_^）:<ul><li>DataSet[Row]</li><li>DataFrame vs RDD<br><img src="https://i.loli.net/2018/12/21/5c1caba0d91e0.jpg" alt="15048413811557"></li><li>DataFrame vs DataSet<ul><li>往往区别是在于行类型的不确定与确定</li></ul></li></ul></li><li>DataSet:<ul><li>repartition: 返回按规则分区后的dataset<ul><li>一句话：分区由少变多，或者在一些不是键值对的RDD中想要重新分区的话，就需要使用repartition了</li><li>有多变少，直接coalesce,repartition其实就是shuffle=true的coalesce</li><li>关于分区：分区的个数决定了并行计算的粒度<ul><li>详情参考：<a href="https://www.zhihu.com/question/31948747" target="_blank" rel="noopener">知乎传送门</a></li></ul></li></ul></li><li>createOrReplaceTempView:<ul><li>创建本地临时‘表’，便于之后sql操作</li></ul></li></ul></li><li>sql:<ul><li>na.drop() 丢掉所有包含null的row</li></ul></li></ul><h3 id="4-线性回归（随机森林类似，换了方法以及ParamMaps）"><a href="#4-线性回归（随机森林类似，换了方法以及ParamMaps）" class="headerlink" title="4. 线性回归（随机森林类似，换了方法以及ParamMaps）"></a>4. 线性回归（随机森林类似，换了方法以及ParamMaps）</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preppedLRPipeline</span></span>():<span class="type">TrainValidationSplit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> lr = <span class="keyword">new</span> <span class="type">LinearRegression</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> paramGrid = <span class="keyword">new</span> <span class="type">ParamGridBuilder</span>()</span><br><span class="line">     .addGrid(lr.regParam, <span class="type">Array</span>(<span class="number">0.1</span>, <span class="number">0.01</span>))</span><br><span class="line">     .addGrid(lr.fitIntercept)</span><br><span class="line">     .addGrid(lr.elasticNetParam, <span class="type">Array</span>(<span class="number">0.0</span>, <span class="number">0.25</span>, <span class="number">0.5</span>, <span class="number">0.75</span>, <span class="number">1.0</span>))</span><br><span class="line">     .build()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> pipeline = <span class="keyword">new</span> <span class="type">Pipeline</span>()</span><br><span class="line">     .setStages(<span class="type">Array</span>(stateHolidayIndexer, schoolHolidayIndexer,</span><br><span class="line">       stateHolidayEncoder, schoolHolidayEncoder, storeEncoder,</span><br><span class="line">       dayOfWeekEncoder, dayOfMonthEncoder,</span><br><span class="line">       assembler, lr))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> tvs = <span class="keyword">new</span> <span class="type">TrainValidationSplit</span>()</span><br><span class="line">     .setEstimator(pipeline)</span><br><span class="line">     .setEvaluator(<span class="keyword">new</span> <span class="type">RegressionEvaluator</span>)</span><br><span class="line">     .setEstimatorParamMaps(paramGrid)</span><br><span class="line">     .setTrainRatio(<span class="number">0.75</span>)</span><br><span class="line">    tvs</span><br><span class="line">&#125;</span><br><span class="line">``` </span><br><span class="line">* <span class="type">LinearRegression</span>:</span><br><span class="line">    * spark mllib自带的线性回归，支持多种类型的正则方法（具体算法迷茫中）</span><br><span class="line">        * <span class="type">Lasso</span> <span class="type">L1</span></span><br><span class="line">        * ridge <span class="type">L2</span></span><br><span class="line">        * elastic net <span class="type">L2</span> + <span class="type">L1</span>   </span><br><span class="line">        * none   </span><br><span class="line">* <span class="type">ParamGridBuilder</span>:</span><br><span class="line">    * 参数网格：</span><br><span class="line">        * 通过不同参数的组合，形成大量参数调优组合后的模型</span><br><span class="line">        * 然后用对应的验证评估方法去择优</span><br><span class="line">    * regParam:定义规范化项的权重</span><br><span class="line">    * elasticNetParam:<span class="type">Elastic</span> net参数，取值介于<span class="number">0</span>，<span class="number">1</span></span><br><span class="line">    * 这里elaticNetParam设置<span class="number">5</span>个值，regParam2个值，代表会有 <span class="number">5</span>*<span class="number">2</span>=<span class="number">10</span>个不同的模型被训练。</span><br><span class="line">* <span class="type">Pipeline</span>:</span><br><span class="line">    * 由一个个stages组成，每一个stage可以是estimator或者transformer</span><br><span class="line">    * fit model时触发</span><br><span class="line">* <span class="type">TrainValidationSplit</span>:</span><br><span class="line">    * 参数调整检验。</span><br><span class="line">    * 随机将输入的dataset划分为训练集和验证集，使用评估机制选择效果最好的模型。</span><br><span class="line">* <span class="type">RegressionEvaluator</span>:</span><br><span class="line">    * 上面说的用于验证模型效果的evaluator</span><br><span class="line"></span><br><span class="line">### <span class="number">5.</span> 模型训练与验证</span><br><span class="line"></span><br><span class="line">``` scala</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fitModel</span></span>(tvs:<span class="type">TrainValidationSplit</span>, data:<span class="type">DataFrame</span>) = &#123;</span><br><span class="line">    <span class="keyword">val</span> <span class="type">Array</span>(training, test) = data.randomSplit(<span class="type">Array</span>(<span class="number">0.8</span>, <span class="number">0.2</span>), seed = <span class="number">12345</span>)</span><br><span class="line">    logger.info(<span class="string">"Fitting data"</span>)</span><br><span class="line">    <span class="keyword">val</span> model = tvs.fit(training)</span><br><span class="line">    logger.info(<span class="string">"Now performing test on hold out set"</span>)</span><br><span class="line">    <span class="keyword">val</span> holdout = model.transform(test).select(<span class="string">"prediction"</span>,<span class="string">"label"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// have to do a type conversion for RegressionMetrics</span></span><br><span class="line">    <span class="keyword">val</span> rm = <span class="keyword">new</span> <span class="type">RegressionMetrics</span>(holdout.rdd.map(x =&gt;</span><br><span class="line">      (x(<span class="number">0</span>).asInstanceOf[<span class="type">Double</span>], x(<span class="number">1</span>).asInstanceOf[<span class="type">Double</span>])))</span><br><span class="line"></span><br><span class="line">    logger.info(<span class="string">"Test Metrics"</span>)</span><br><span class="line">    logger.info(<span class="string">"Test Explained Variance:"</span>)</span><br><span class="line">    logger.info(rm.explainedVariance)</span><br><span class="line">    logger.info(<span class="string">"Test R^2 Coef:"</span>)</span><br><span class="line">    logger.info(rm.r2)</span><br><span class="line">    logger.info(<span class="string">"Test MSE:"</span>)</span><br><span class="line">    logger.info(rm.meanSquaredError)rm = <span class="keyword">new</span> <span class="type">RegressionMetrics</span>(holdout.rdd.map(x =&gt;</span><br><span class="line">      (x(<span class="number">0</span>).asInstanceOf[<span class="type">Double</span>], x(<span class="number">1</span>).asInstanceOf[<span class="type">Double</span>])))</span><br><span class="line"></span><br><span class="line">    logger.info(<span class="string">"Test Metrics"</span>)</span><br><span class="line">    logger.info(<span class="string">"Test Explained Variance:"</span>)</span><br><span class="line"></span><br><span class="line">    logger.info(<span class="string">"Test RMSE:"</span>)</span><br><span class="line">    logger.info(rm.rootMeanSquaredError)</span><br><span class="line"></span><br><span class="line">    model</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>首先划分训练集和测试集</li><li>fit：<ul><li>用训练集拟合出一个model</li></ul></li><li>RegressionMetrics:<ul><li>回归evaluator</li><li>集中评估标准：<ul><li>R^2：决定系数，反应因变量的全部变异能通过回归关系被自变量解释的比例。如R平方为0.8，则表示回归关系可以解释因变量80%的变异。换句话说，如果我们能控制自变量不变，则因变量的变异程度会减少80%</li><li>explainedVariance: 解释方差，具体详见：<a href="http://blog.sciencenet.cn/blog-1148346-852482.html" target="_blank" rel="noopener">http://blog.sciencenet.cn/blog-1148346-852482.html</a></li><li>MAE mean absolute error: 绝对误差，准确值与其测量值之间的误差。</li><li>MSE mean squared error: 均方误差, 衡量平均误差的方法。</li><li>RMSE root mean square error: 均方根误差。</li></ul></li></ul></li><li>最后用训练好的模型transform测试集，然后将结果保存。</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="http://sparktutorials.net/spark-mllib---predict-store-sales-with-ml-pipelines" target="_blank" rel="noopener">Spark MLLib - Predict Store Sales with ML Pipelines</a></li><li><a href="http://spark.apache.org/docs/latest/api/scala/index.html#package" target="_blank" rel="noopener">Spark doc</a></li><li><a href="http://dblab.xmu.edu.cn/blog/1510-2/" target="_blank" rel="noopener">Spark2.1.0入门：模型选择和超参数调整</a></li><li><a href="Spark2 Linear Regression线性回归">Spark2 Linear Regression线性回归</a></li><li><a href="http://blog.csdn.net/tuntunwang/article/details/60870312" target="_blank" rel="noopener">基于spark用线性回归（linear regression)进行数据预测</a></li><li><a href="http://www.jianshu.com/p/200473f264bc" target="_blank" rel="noopener">Intellij之Spark Scala开发环境搭建</a></li><li><a href="http://dblab.xmu.edu.cn/blog/1297-2/" target="_blank" rel="noopener">Spark入门：标签和索引的转化：StringIndexer- IndexToString-VectorIndexer</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本文重在借案例学习spark相关数据结构与语法&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;流程&quot;&gt;&lt;a href=&quot;#流程&quot; class=&quot;headerlink&quot; title=&quot;流程&quot;&gt;&lt;/a&gt;流程&lt;/h2&gt;&lt;h3 id=&quot;1-特征转换&quot;
      
    
    </summary>
    
      <category term="ML" scheme="/categories/ML/"/>
    
    
  </entry>
  
  <entry>
    <title>爱乐之城</title>
    <link href="/2017/03/18/%E7%88%B1%E4%B9%90%E4%B9%8B%E5%9F%8E/"/>
    <id>/2017/03/18/爱乐之城/</id>
    <published>2017-03-18T15:12:11.000Z</published>
    <updated>2017-11-10T01:18:12.436Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>一部好电影，总是能触响你内心的共鸣，爱乐之城就是这样一部好电影。</p></blockquote><h2 id="好电影应该包含什么"><a href="#好电影应该包含什么" class="headerlink" title="好电影应该包含什么"></a>好电影应该包含什么</h2><ul><li>引人共鸣的音乐</li><li>好故事</li><li>好结局</li><li>引人深思</li></ul><h2 id="共鸣"><a href="#共鸣" class="headerlink" title="共鸣"></a>共鸣</h2><h3 id="梦想"><a href="#梦想" class="headerlink" title="梦想"></a>梦想</h3><p>每个人都有拥有梦想的权利，年轻就应该去追逐，无惧失败。在追逐梦想的道路上，除了自己的那份坚持之外，最可贵的就是能有一个人在激励与支持你（原来想说默默的支持，看到塞的方式之后，感觉如果你打算支持她就要把这份支持高调的表达出来，并从内心真正的认可对方）。</p><p>最近关于梦想的讨论好多，听了马老师的演讲后，跟同事在一起也讨论了好久。很多梦想可能需要在财务自由后才能实现，为了梦想可能中途需要做很多妥协。这些妥协，对于像我们这样支身前往异地的伪单身们应该感受会更加强烈。在“家”的城市里的温暖，为了追逐自己的梦想消失了，为了梦想，妥协的不只是自己的那份还有属于家人的那份温暖。所以，我们既然为了梦想放弃了这么多，有什么理由不加倍努力呢。</p><h3 id="选择"><a href="#选择" class="headerlink" title="选择"></a>选择</h3><p>选择，每个人这辈子都会经历各种各样的选择。电影中，用一些表现形式，让大家可以看到主角们不同选择所后续形成的生活轨迹。这点让我回忆起凯奇的《居家男人》，不过结局不同，居家男人的凯奇最后还有再选择的机会与命运，而塞巴斯蒂安则选择了祝福、接受以及把那份对米娅的爱深深藏在心里。</p><p>选择，有的时候就是这样，你不选择永远不知道什么才是你想要的。但一定要知道哪些是不能割舍的，如果触碰了它，就没有选择的余地了。一旦失去了唾手可得的幸福，可能想要再追逐回来就太难了或者也许已经不可能了吧。我想塞看到米娅身边的人，内心想了很多，米娅已经有了自己新的生活，有了身边这个同样爱她的人，也许也已经有了一个完整的家庭，从米娅临走时的微笑，他确认到了这一点，那么这也是他想要给米娅带来的幸福，所以他的内心也就坦然接受了现实。</p><p>选择过了，那么就要为自己的选择负责。如果选择是错误的，可以尝试努力追回，但不要影响这个世界的轨迹。</p><h3 id="一种“真爱”的诠释"><a href="#一种“真爱”的诠释" class="headerlink" title="一种“真爱”的诠释"></a>一种“真爱”的诠释</h3><p>命运之神有时候就是那么喜欢开玩笑，有时候硬把两个毫不相干的人拽在一起，想不在一起都不行，然后却又会突然切断这份羁绊。</p><p>塞对米娅的爱是毋庸置疑的，就像他为米娅一直弹奏的那首钢琴曲，一直没有变。我觉得其实米娅最后没有选择跟塞在一起其实也是电影在映射现实。现实就是这样，唯一不变的就是变化，正是有了这些偶然才构成了生活。但从米娅对塞的回笑，可以感受到米娅还深爱着塞，但是生活还是要继续下去。</p><p>爱一个人，要去从内心支持对方的梦想，允许对方的偶尔发泄，毕竟我们都是人，都会有各种感情，就像哈佛幸福课中Tal所说的Permision to be human。爱一个人，要学会接受对方的选择，如果对方是幸福的，如果不能相守，也要释然的祝福它。</p><h3 id="生活与幸福"><a href="#生活与幸福" class="headerlink" title="生活与幸福"></a>生活与幸福</h3><p>生活代表着变化与偶然，而幸福则属于积极心理学的范畴，关于幸福感兴趣可以尝试听一下哈佛幸福课。</p><p>追逐梦想是幸福的，电影最后，可以说塞和米娅的梦想都实现了，但是属于他们之间的幸福却失去了。前面是幸福的范畴，后面是生活的范畴。</p><p>生活中的有些幸福，往往跟物质生活是无关的（当然要满足基本的物质需求）。就像塞跟米娅相爱之初，他们像一般情侣一样，天天黏在一起是幸福的。但是塞为了支持米娅的梦想，去接受乐队的工作，聚少离多的日子，他们的生活轨迹开始出现岔路，幸福也在悄然变化。</p><p>有时候幸福悄悄的藏了起来，不易发现，要去找到它，并把它与自己的梦想系在一起，因为可能不经意间割舍掉的幸福说不定就是自己梦想的最终故里。</p><h2 id="尾记"><a href="#尾记" class="headerlink" title="尾记"></a>尾记</h2><p>挺好的一部电影，好久没有这种抑制不住情感的时刻，也许跟自己当下的生活相关吧。追逐梦想，珍视幸福，不要让它们在你的指尖溜走。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;一部好电影，总是能触响你内心的共鸣，爱乐之城就是这样一部好电影。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;好电影应该包含什么&quot;&gt;&lt;a href=&quot;#好电影应该包含什么&quot; class=&quot;headerlink&quot; title=&quot;好电影应该包含
      
    
    </summary>
    
      <category term="影评" scheme="/categories/%E5%BD%B1%E8%AF%84/"/>
    
    
  </entry>
  
  <entry>
    <title>哈佛幸福课小结</title>
    <link href="/2017/02/12/%E5%93%88%E4%BD%9B%E5%B9%B8%E7%A6%8F%E8%AF%BE%E5%B0%8F%E7%BB%93/"/>
    <id>/2017/02/12/哈佛幸福课小结/</id>
    <published>2017-02-12T12:22:35.000Z</published>
    <updated>2017-11-10T01:18:12.436Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="鸡汤乱炖" scheme="/categories/%E9%B8%A1%E6%B1%A4%E4%B9%B1%E7%82%96/"/>
    
    
  </entry>
  
</feed>
